{"cells":[{"cell_type":"markdown","metadata":{"id":"h1wWTKJIZwNn"},"source":["## Homophobic lyrics detection - Binary Classification"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28806,"status":"ok","timestamp":1713915490139,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"},"user_tz":360},"id":"4jKe6Z88t8cS","outputId":"023420a7-2379-4e2d-e8f4-3545b42834e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"t0e9ZYbX_Zdb","executionInfo":{"status":"ok","timestamp":1713915490139,"user_tz":360,"elapsed":3,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/HOMO-MEX/task_3')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Mju2plfz-9Ol","executionInfo":{"status":"ok","timestamp":1713915497740,"user_tz":360,"elapsed":7604,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["from config import config"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Kz1-GDwGWKet","executionInfo":{"status":"ok","timestamp":1713915563559,"user_tz":360,"elapsed":65821,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["%%capture\n","#! pip install --quiet \"torchvision\" \"torch>==1.10\" \"pytorch-lightning>=1.3\" \"torchmetrics>=0.3\" \"typing-extensions<4,>=3.7.4.3\" \"tf-estimator-nightly==2.8.0.dev2021122109\" \"folium==0.2.1\"\n","! pip install torchmetrics"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"H5u7HouB5KAH","executionInfo":{"status":"ok","timestamp":1713915571119,"user_tz":360,"elapsed":7565,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["%%capture\n","!pip install transformers # pre-trained models from https://huggingface.co/"]},{"cell_type":"markdown","metadata":{"id":"bstJaTW7bkVI"},"source":["### Import all the libraries and functions we will use"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_YZaDj3XPY79","executionInfo":{"status":"ok","timestamp":1713915578131,"user_tz":360,"elapsed":7014,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["import re\n","import os\n","import time\n","import datetime\n","import random\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoModel\n","\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, SequentialSampler\n","\n","from torchmetrics.classification import MulticlassF1Score, BinaryF1Score\n","\n","pd.set_option('display.max_colwidth',None)"]},{"cell_type":"markdown","metadata":{"id":"Kfv-X7UtcIS6"},"source":["### Environment set up\n"]},{"cell_type":"markdown","metadata":{"id":"uR_76GQMaWO7"},"source":["Select the device where the model is to be trained."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1713915578131,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"},"user_tz":360},"id":"MWmfcRibcSEa","outputId":"a953aec4-f0e7-4b89-879f-9acf4a58433a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":7}],"source":["run_on = 'cuda' if torch.cuda.is_available() else 'cpu'\n","DEVICE = torch.device(run_on)\n","DEVICE"]},{"cell_type":"markdown","metadata":{"id":"7cJHIgIpPY8X"},"source":["Set a random seed to ensure that the results are reproducible when attempting to run this *notebook* again."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ucyAVWNSPY8c","executionInfo":{"status":"ok","timestamp":1713915578132,"user_tz":360,"elapsed":8,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["# set random seed\n","def set_seed(value):\n","    random.seed(value)\n","    np.random.seed(value)\n","    torch.manual_seed(value)\n","    torch.cuda.manual_seed_all(value)\n","\n","set_seed(config.RANDOM_STATE)"]},{"cell_type":"markdown","metadata":{"id":"9yQwYzSucWXF"},"source":["### Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"f6vZ9M6OneuC","executionInfo":{"status":"ok","timestamp":1713915613743,"user_tz":360,"elapsed":363,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["class CustomDataset:\n","  def __init__(self, datapath, version, batch_size, modelname, test_size=0.2):\n","    self.datapath = datapath\n","    self.batch_size = batch_size\n","    self.dataloaders = {}\n","    self.dfs = {}\n","    self.tokenizer = AutoTokenizer.from_pretrained(modelname\n","                                          ,do_lower_case=(True if 'uncased' in modelname else False))\n","    self.prepareData(version)\n","\n","  def prepareData_kfold(self):\n","    df = pd.read_csv(self.datapath, converters={ config.TEXT:str, config.TARGET:str })\n","    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","    df[\"label\"] = df[\"label\"].map({ \"P\": 0, \"NP\": 1 })\n","\n","    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=config.RANDOM_STATE)\n","    kfolds = skf.split(df[config.TEXT], df[config.TARGET])\n","\n","    for i, (train_index, test_index) in enumerate(kfolds):\n","      train = df.iloc[list(train_index)]\n","      test = df.iloc[list(test_index)]\n","\n","      train = train.sample( len(train), random_state=config.RANDOM_STATE )\n","      test = test.sample( len(test), random_state=config.RANDOM_STATE )\n","\n","      self.dfs[i] = { \"train\": train, \"val\": test }\n","      self.dataloaders[i] = { \"train\": self.getTensorDataset(train), \"val\": self.getTensorDataset(test) }\n","\n","    return self.dataloaders\n","\n","  def prepareData(self, version):\n","    dataset_names = [ \"train\", \"dev\", \"test\" ]\n","    for key in dataset_names:\n","      df = pd.read_csv(f\"{self.datapath}{key}_{version}.csv\", converters={ config.TEXT:str })\n","      if key == \"train\":\n","        class1 = df[ df[config.TARGET] == \"P\"]\n","        class2 = df[ df[config.TARGET] == \"NP\"].sample(146, random_state=config.RANDOM_STATE)\n","        df = pd.concat([ class1, class2 ])\n","        df = df.sample( len(df), random_state=config.RANDOM_STATE )\n","\n","      inputs, masks = self.tokenize(df[\"text\"])\n","\n","      if config.TARGET in list(df.columns):\n","        df[config.TARGET] = df[config.TARGET].map({ \"P\": 0, \"NP\": 1 })\n","        labels = torch.tensor(df[config.TARGET].to_numpy(), dtype=torch.long)\n","        data = TensorDataset(inputs, masks, labels)\n","      else:\n","        df[config.ID] = df[config.ID].apply(lambda x: int(x.replace(\"_Track3\", \"\")))\n","        ids = torch.tensor(df[config.ID].to_numpy(), dtype=torch.long)\n","        data = TensorDataset(inputs, masks, ids)\n","\n","      sampler = SequentialSampler(data)\n","      self.dfs[key] = df\n","      self.dataloaders[key] = DataLoader(data,\n","                                         sampler=sampler,\n","                                         batch_size=self.batch_size,\n","                                         num_workers=0)\n","      print(\"...dataloader for\", key, \"completed\")\n","    return self.dataloaders\n","\n","  def getTensorDataset(self, dataset):\n","    inputs, masks = self.tokenize(dataset[config.TEXT])\n","    labels = torch.tensor(dataset[config.TARGET].to_numpy(), dtype=torch.float32)\n","    data = TensorDataset(inputs, masks, labels)\n","    sampler = SequentialSampler(data)\n","    dataloader = DataLoader(data, sampler=sampler, batch_size=self.batch_size, num_workers=0)\n","    return dataloader\n","\n","  def tokenize(self, dataset):\n","    input_ids = []\n","    attention_mask = []\n","\n","    for doc in dataset:\n","      encoded_doc = self.tokenizer.encode_plus(doc,\n","                                          add_special_tokens=True,\n","                                          max_length=config.TASK3_MAXLEN,\n","                                          truncation=True,\n","                                          padding=\"max_length\",\n","                                          return_token_type_ids=False\n","                                          )\n","\n","      input_ids.append(encoded_doc['input_ids'])\n","      attention_mask.append(encoded_doc['attention_mask'])\n","\n","    return (torch.tensor(input_ids), torch.tensor(attention_mask))"]},{"cell_type":"markdown","metadata":{"id":"yjxzchnTfs_N"},"source":["### Training\n","\n","This process consists of transforming the words of the messages into features expected by BETO.\n"]},{"cell_type":"code","source":["# PARAMETERS\n","import math\n","\n","# Model\n","NUM_LABELS = 2\n","TARGET_NAMES = [\"P\", \"NP\"]\n","\n","# Training\n","BATCH_SIZE = 8\n","GRADIENT_ACCUMULATOR_SIZE = 1\n","NUM_EPOCHS = 10\n","\n","GET_ATTENTIONS = False\n","GET_HIDDEN_STATES = False\n","DROPOUT = 0.05\n","\n","# Optimizer\n","LR = 4e-5\n","EPS = 1e-10\n","WEIGHT_DECAY = 0\n","BETAS = (0.9, 0.999)\n","AMSGRAD = False\n","\n","# Loss\n","REDUCTION = \"sum\"\n","LABEL_SMOOTHING = 0\n","\n","# Scheduler\n","POWER = 1.0"],"metadata":{"id":"8UkS1XgJF_dT","executionInfo":{"status":"ok","timestamp":1713915622574,"user_tz":360,"elapsed":314,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"mfsStD_9wlZ8","executionInfo":{"status":"ok","timestamp":1713915623662,"user_tz":360,"elapsed":4,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["#fuction to format time\n","def format_time(elapsed):\n","  elapsed_rounded = int(round((elapsed)))\n","  return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","#function to clean cuda memory\n","def clean_cuda_memory(iterable_var):\n","  for elem in iterable_var:\n","    elem.to('cpu')\n","    del elem\n","  torch.cuda.empty_cache()\n","  gc.collect()\n","\n","def get_class_weights(classes_list, labels):\n","  return compute_class_weight('balanced', classes=classes_list, y=labels)\n","\n","#variable to plot the confusion matrix\n","conf = []"]},{"cell_type":"code","source":["class TextClassifier(nn.Module):\n","    def __init__(self, modelpath, freeze_model=False, num_labels=2, get_att=False, get_hs=False, dropout=0.05):\n","        super(TextClassifier, self).__init__()\n","        self.bert = AutoModel.from_pretrained(modelpath\n","                                              ,num_labels=num_labels\n","                                              ,output_attentions=get_att\n","                                              ,output_hidden_states=get_hs)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n","        self.freeze_model = freeze_model\n","\n","        if self.freeze_model:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids\n","                            ,token_type_ids=None\n","                            ,attention_mask=attention_mask)\n","\n","        pooled_output = outputs.pooler_output\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.fc(pooled_output)\n","        return logits"],"metadata":{"id":"JfhU2Zm0-8q7","executionInfo":{"status":"ok","timestamp":1713915623662,"user_tz":360,"elapsed":3,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"aPq566wnZ8kc","executionInfo":{"status":"ok","timestamp":1713915623662,"user_tz":360,"elapsed":3,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["class CustomModel:\n","  def __init__(self, modelpath, class_weights):\n","    self.model = TextClassifier(modelpath, num_labels=NUM_LABELS, get_att=GET_ATTENTIONS, get_hs=GET_HIDDEN_STATES, dropout=DROPOUT)\n","\n","    self.optimizer = torch.optim.Adam(self.model.parameters()\n","                                      ,lr = LR\n","                                      ,eps = EPS\n","                                      ,weight_decay = WEIGHT_DECAY\n","                                      ,betas = BETAS # 0.9, 0.999\n","                                      ,amsgrad = AMSGRAD)\n","\n","    self.criterion = nn.CrossEntropyLoss(weight=class_weights # torch.tensor([5.8, 0.43, 2]).to(device)\n","                                         ,reduction = REDUCTION #sum\n","                                         ,label_smoothing = LABEL_SMOOTHING)\n","\n","  def freeze_all(self):\n","    #Freeze all layers except classifier\n","    for name, param in self.model.named_parameters():\n","      if \"encoder.layer\" in name:\n","        param.requires_grad = False\n","\n","  def unfreeze(self, layers=np.arange(0,13,1)):\n","    self.freeze_all()\n","    #Unfreeze specified layers\n","    for layer_no in layers:\n","      for name, param in self.model.named_parameters():\n","        if \"encoder.layer\" in name and str(layer_no) in name:\n","          param.requires_grad = True\n","\n","  def freeze_embs(self):\n","    for name, param in self.model.named_parameters():\n","      if \"embeddings\" in name:\n","        param.requires_grad = False\n","\n","  def validation(self, val_dataloader):\n","    t0 = time.time()\n","\n","    # We put the model in validation mode\n","    self.model.eval()\n","\n","    # We declare variables\n","    eval_loss = 0\n","    eval_metric = 0\n","    all_logits = []\n","    all_labels = []\n","\n","    # By minibatches\n","    for step, batch in enumerate(val_dataloader):\n","      b_input_ids, b_input_mask, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","      with torch.no_grad():\n","        # We generate the predictions of the model\n","        outputs = self.model(b_input_ids,\n","                            attention_mask=b_input_mask)\n","\n","        loss = self.criterion(outputs, b_labels)\n","\n","        # ...we extract them\n","        logits = torch.argmax(outputs, dim=1).detach().cpu()\n","        b_labels = b_labels.to('cpu')\n","\n","        # Saving logits and labels. They will be useful for the confusion matrix.\n","        #predict_labels = np.argmax(logits, axis=1).flatten()\n","        all_logits.extend(logits.tolist())\n","        all_labels.extend(b_labels.tolist())\n","\n","        eval_loss += loss\n","\n","    # We calculate the F1 score of this batch\n","    scores = MulticlassF1Score(num_classes=2, average=None)(torch.tensor(all_logits), torch.tensor(all_labels))\n","    score = BinaryF1Score()(torch.tensor(all_logits), torch.tensor(all_labels))\n","    # We show the final accuracy for this epoch\n","    print(f\"\\n\\tF1Scores: {scores.tolist()}\")\n","    print(f\"\\n\\tEvalLoss: {eval_loss}\")\n","    print(f\"\\tValidation took: {format_time(time.time() - t0)}\")\n","    return scores, eval_loss\n","\n","\n","  def training(self, n_epochs, train_dataloader, val_dataloader, gradient_accumulator_size=2):\n","    max_step_t = len(train_dataloader)\n","    max_step_v = len(val_dataloader)\n","\n","    scheduler = torch.optim.lr_scheduler.PolynomialLR(self.optimizer\n","                                                      ,total_iters=n_epochs\n","                                                      ,power=POWER)\n","\n","    total_loss = []\n","    total_lr = []\n","\n","    for epoch in range(n_epochs):\n","      # for each epoch...\n","      print(f\"\\nEpoch {epoch + 1} / {n_epochs} :\")\n","      # We save the start time to see how long it takes.\n","      t0 = time.time()\n","      # We reset the loss value for each epoch.\n","      epoch_loss = []\n","\n","      # Training mode.\n","      self.model.train()\n","      self.model.zero_grad()\n","\n","      for step, batch in enumerate(train_dataloader):\n","        batch_loss = 0\n","        b_input_ids, b_input_mask, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        # Propagation forward in the layers\n","        outputs = self.model(b_input_ids,\n","                        attention_mask=b_input_mask)\n","\n","        # We calculate the loss of the present minibatch\n","        loss = self.criterion(outputs, b_labels) #outputs[0]\n","        batch_loss += loss.item()\n","        epoch_loss.append( loss.item() )\n","\n","        # Backpropagation\n","        loss.backward()\n","\n","        # So we can implement gradien accumulator technique\n","        if (step > 0 and step % gradient_accumulator_size == 0) or (step == len(train_dataloader) - 1):\n","          #(this prevents the gradient from becoming explosive)\n","          torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n","\n","          # We update the weights and bias according to the optimizer\n","          self.optimizer.step()\n","          # We clean the gradients for the accumulator batch\n","          self.model.zero_grad()\n","\n","        b_input_ids.to(\"cpu\")\n","        b_input_mask.to(\"cpu\")\n","        b_labels.to(\"cpu\")\n","        del b_input_ids\n","        del b_input_mask\n","        del b_labels\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","        if step % 20 == 0 or step == max_step_t - 1:\n","          print(f\"Batch {step}/{max_step_t} avg loss: {np.sum(epoch_loss) / (step+1):.5f} {np.max(epoch_loss):.5f} {np.min(epoch_loss):.5f}\")\n","\n","      #Update learning rate each end of epoch\n","      scheduler.step()\n","      total_lr.append(scheduler.get_last_lr())\n","      total_loss.append(np.sum(epoch_loss)/len(train_dataloader))\n","\n","      # We calculate the average loss in the current epoch of the training set\n","      print(f\"\\n\\tAverage training loss: {np.sum(epoch_loss)/len(train_dataloader):.5f}\")\n","      print(f\"\\tTraining epoch took: {format_time(time.time() - t0)}\")\n","\n","      print(\"\\n\\tValidation\")\n","      curr_score, curr_eval_loss = self.validation(val_dataloader)\n","\n","    # Display learning rate and loss charts\n","    epoch_axis = np.arange(0, n_epochs) + 1\n","    plt.plot(epoch_axis, total_loss)\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"loss\")\n","    plt.xticks(epoch_axis)\n","    plt.show()\n","\n","    \"\"\"\n","    print(\"\\n\\n\")\n","\n","    plt.plot(epoch_axis, total_lr)\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"learning rate\")\n","    plt.xticks(epoch_axis)\n","    plt.show()\n","    \"\"\"\n","    print(\"\\nTraining complete\")\n","\n","\n","  def testing(self, dataloader):\n","    preds = []\n","    labs = []\n","\n","    with torch.no_grad():\n","      for step, batch in enumerate(dataloader):\n","        test_inputs, test_masks, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        outputs = self.model(test_inputs,\n","                             attention_mask=test_masks)\n","\n","        logits = torch.argmax(outputs, dim=1).detach().cpu()\n","        b_labels = b_labels.to('cpu').tolist()\n","\n","        preds.extend([x.item() for x in logits])\n","        labs.extend(b_labels)\n","\n","    preds = [ \"P\" if pred == 0 else \"NP\" for pred in preds ]\n","    labs = [ str(l) + \"_Track3\" for l in labs ]\n","\n","    dataframe_res = { \"sub_id\": labs, \"label\": preds }\n","    dataframe_res = pd.DataFrame.from_dict(dataframe_res)\n","\n","    return dataframe_res\n","\n","  def metrics_testing(self, dataloader):\n","    preds = []\n","    labs = []\n","\n","    with torch.no_grad():\n","      for step, batch in enumerate(dataloader):\n","        test_inputs, test_masks, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        outputs = self.model(test_inputs,\n","                             attention_mask=test_masks)\n","\n","        logits = torch.argmax(outputs, dim=1).detach().cpu()\n","        b_labels = b_labels.to('cpu').tolist()\n","\n","        preds.extend([x.item() for x in logits])\n","        labs.extend(b_labels)\n","\n","    return preds, labs"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ibe3moZGu7i1","executionInfo":{"status":"ok","timestamp":1713915623662,"user_tz":360,"elapsed":3,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","def report_metrics(data):\n","  preds, targets = data[0], data[1]\n","  print(classification_report(targets, preds, target_names=TARGET_NAMES, digits=4))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"_gUjJXYjqcZ4","executionInfo":{"status":"ok","timestamp":1713915623662,"user_tz":360,"elapsed":3,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[],"source":["import gc\n","\n","def fine_tuning_kfold(layers, desc, modelname, num_epochs = 10, embeddings = True, gradient_accumulator_size = 4):\n","  for kfold in datasets.dataloaders:\n","    if kfold > 2:\n","      break\n","\n","    train = datasets.dataloaders[kfold][\"train\"]\n","    dev = datasets.dataloaders[kfold][\"val\"]\n","    train_count = datasets.dfs[kfold][\"train\"][config.TEXT].count()\n","    dev_count = datasets.dfs[kfold][\"val\"][config.TEXT].count()\n","    print(f\"K-Fold: {kfold} -->  train size:{ train_count } val size:{ dev_count }\")\n","    print(\"------------------------\")\n","\n","    class_weights = get_class_weights([0,1], datasets.dfs[kfold][\"train\"][config.TARGET])\n","    print(f\"class weights: {class_weights}\")\n","    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n","    m = CustomModel(modelname, class_weights)\n","    m.unfreeze(layers)\n","\n","    if not embeddings:\n","      m.freeze_embs()\n","\n","    m.model.to(DEVICE)\n","    m.training(num_epochs, train, dev)\n","\n","    # m.model.save_pretrained(f\"{config.MODELPATH}{config.TRAINED_BETO}_{str(kfold)}\")\n","    print(\"Training complete. Validation results:\\n\")\n","    report_metrics(m.testing(dev))\n","\n","    m.model.to(\"cpu\")\n","    del m\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","#TODO : save best model and prepare test results\n","def fine_tuning(layers, desc, modelname, num_epochs = 10, embeddings = True, gradient_accumulator_size = 4):\n","  train = datasets.dataloaders[\"train\"]\n","  dev = datasets.dataloaders[\"dev\"]\n","  test = datasets.dataloaders[\"test\"]\n","\n","  train_count = datasets.dfs[\"train\"][config.TEXT].count()\n","  dev_count = datasets.dfs[\"dev\"][config.TEXT].count()\n","\n","  print(f\"train_size:{ train_count }   val_size:{ dev_count }\")\n","  print(\"------------------------\")\n","\n","  class_weights = get_class_weights([0,1], datasets.dfs[\"train\"][config.TARGET])\n","  #class_weights[0] = class_weights[0] * 2\n","  print(f\"class weights: {class_weights}\")\n","  class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n","  m = CustomModel(modelname, class_weights)\n","  m.unfreeze(layers)\n","\n","  if not embeddings:\n","    m.freeze_embs()\n","\n","  m.model.to(DEVICE)\n","  m.training(num_epochs, train, dev)\n","  df_res = m.testing(test)\n","  df_res.to_csv(config.TRACK3 + \"tests/test_maria.csv\")\n","  # m.model.save_pretrained(f\"{config.MODELPATH}{config.TRAINED_BETO}_{str(kfold)}\")\n","  print(\"Training complete. Validation results:\\n\")\n","  report_metrics(m.metrics_testing(dev))\n","\n","  m.model.to(\"cpu\")\n","  del m\n","  torch.cuda.empty_cache()\n","  gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"eIUDQ18nP50P"},"source":["V1"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"kuBdOqcl_870","colab":{"base_uri":"https://localhost:8080/","height":324,"referenced_widgets":["8a54b70e99d9403c97810de77b6ade75","211800000b254f25b32f2ec3e86a8c4e","2f027d0857b646c09efceedad2e91dd9","c358159c27b44893889998a1d309ad8b","50cc5e86845048aeaf16f586aad1de7d","0d2fb95ecd8c4a7f95f8572fd03c0c2e","7538785eb387434993b93c3b8495381a","f82d9d2578754985a12134b116c51339","6a266688457c45f5a1db5970d327dafa","e8f6ef62fe46436cad20be95460c9fae","46f3ec8d6db147c5ab54e31c0a15a58e","4b17e292de394e6fa5e55b007a9a13d7","7cb9341926ef4f7fa5614b305d7a26d6","db77610693c14f4a82eecdfefb84123f","5088b4491cef4db48cf4b95b6c2cf7ac","f63fdd7ed2a4481b8927b75cbeb5b079","a44250ea8ca74c4bbef8605f8a87aabe","180a8685f6244815aa28eb938fcec220","fae4e006d2d443c987ec12704b5cf9b7","2267d534bac14e84a5e98e859479d975","ff029217ca6d41ffabec09915cd55706","c5af393892594437bbef55af0294fb04","d8b19dcba2374369b9ec8c60c60967ae","60caca7b4c794d68803001ab0a6342bc","1ecb69a80093464ebb94d696556986fe","1a4b9be19fda45a7bd7ce42ce97f82c1","ee2199973e264e1c8a6c72c469bfd55c","dd301e3f15354038bc1bfa29ee59c394","e9f6596304f24247b026d55d699e12ad","65b9f2cb2c8c40a5a1bf0e9db9f25d35","d204c6bd110342b4bea9bf05ee532f9d","6c882db831a64692b43f0044810fccf1","3c520d4e14bf4c4d86930ca755846387"]},"executionInfo":{"status":"ok","timestamp":1713915634795,"user_tz":360,"elapsed":11136,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}},"outputId":"0ca44bac-fa73-46ff-8314-e99b67e42506"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a54b70e99d9403c97810de77b6ade75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b17e292de394e6fa5e55b007a9a13d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8b19dcba2374369b9ec8c60c60967ae"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["...dataloader for train completed\n","...dataloader for dev completed\n","...dataloader for test completed\n"]}],"source":["#Obtener datasets\n","datasets = CustomDataset(config.TRACK3,\n","                         version = \"v1\",\n","                         batch_size = BATCH_SIZE,\n","                         modelname = config.C_MDEBERTA)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"YL7SvLt3JYmb","colab":{"base_uri":"https://localhost:8080/","height":908,"referenced_widgets":["7e689cd07c284307ac8b405215c6bf97","df943c2847444885acaf5b65304ce55e","2e8f6ad4d5854fca88219a749600869e","42a12c4bf0f14ac8938f5d2fe80fde55","96616eb78e904228b744b2128ab4db3c","823784509bad4fc282534b8f204b6532","b26a3a2914e04ba3a2d37b8e55154beb","101c08b6021b47e990201554884ac6e9","c52aca9c6b394fc19de10c232992dc90","6bbf6df69a20444eb9636aec354611ac","c92d42a597c2433b9378ca54df18bb49"]},"executionInfo":{"status":"error","timestamp":1713915646211,"user_tz":360,"elapsed":11418,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}},"outputId":"591e263f-7f35-4525-b2a9-6381487cb625"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_size:292   val_size:600\n","------------------------\n","class weights: [1. 1.]\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e689cd07c284307ac8b405215c6bf97"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 / 10 :\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'BaseModelOutput' object has no attribute 'pooler_output'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-7728a070b26a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfine_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all_layers_cased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_MDEBERTA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_accumulator_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGRADIENT_ACCUMULATOR_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-f3d3993ce60e>\u001b[0m in \u001b[0;36mfine_tuning\u001b[0;34m(layers, desc, modelname, num_epochs, embeddings, gradient_accumulator_size)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0mdf_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0mdf_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRACK3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"tests/test_maria.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-b9471e727efd>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, n_epochs, train_dataloader, val_dataloader, gradient_accumulator_size)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Propagation forward in the layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         outputs = self.model(b_input_ids,\n\u001b[0m\u001b[1;32m    108\u001b[0m                         attention_mask=b_input_mask)\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-a005e8e4223c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m                             ,attention_mask=attention_mask)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutput' object has no attribute 'pooler_output'"]}],"source":["layers = [str(x) for x in range(0, 12)]\n","fine_tuning(layers, \"all_layers_cased\", config.C_MDEBERTA, num_epochs=NUM_EPOCHS, gradient_accumulator_size=GRADIENT_ACCUMULATOR_SIZE)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8a54b70e99d9403c97810de77b6ade75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_211800000b254f25b32f2ec3e86a8c4e","IPY_MODEL_2f027d0857b646c09efceedad2e91dd9","IPY_MODEL_c358159c27b44893889998a1d309ad8b"],"layout":"IPY_MODEL_50cc5e86845048aeaf16f586aad1de7d"}},"211800000b254f25b32f2ec3e86a8c4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d2fb95ecd8c4a7f95f8572fd03c0c2e","placeholder":"​","style":"IPY_MODEL_7538785eb387434993b93c3b8495381a","value":"tokenizer_config.json: 100%"}},"2f027d0857b646c09efceedad2e91dd9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f82d9d2578754985a12134b116c51339","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a266688457c45f5a1db5970d327dafa","value":52}},"c358159c27b44893889998a1d309ad8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8f6ef62fe46436cad20be95460c9fae","placeholder":"​","style":"IPY_MODEL_46f3ec8d6db147c5ab54e31c0a15a58e","value":" 52.0/52.0 [00:00&lt;00:00, 3.67kB/s]"}},"50cc5e86845048aeaf16f586aad1de7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d2fb95ecd8c4a7f95f8572fd03c0c2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7538785eb387434993b93c3b8495381a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f82d9d2578754985a12134b116c51339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a266688457c45f5a1db5970d327dafa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8f6ef62fe46436cad20be95460c9fae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f3ec8d6db147c5ab54e31c0a15a58e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b17e292de394e6fa5e55b007a9a13d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cb9341926ef4f7fa5614b305d7a26d6","IPY_MODEL_db77610693c14f4a82eecdfefb84123f","IPY_MODEL_5088b4491cef4db48cf4b95b6c2cf7ac"],"layout":"IPY_MODEL_f63fdd7ed2a4481b8927b75cbeb5b079"}},"7cb9341926ef4f7fa5614b305d7a26d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a44250ea8ca74c4bbef8605f8a87aabe","placeholder":"​","style":"IPY_MODEL_180a8685f6244815aa28eb938fcec220","value":"config.json: 100%"}},"db77610693c14f4a82eecdfefb84123f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae4e006d2d443c987ec12704b5cf9b7","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2267d534bac14e84a5e98e859479d975","value":579}},"5088b4491cef4db48cf4b95b6c2cf7ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff029217ca6d41ffabec09915cd55706","placeholder":"​","style":"IPY_MODEL_c5af393892594437bbef55af0294fb04","value":" 579/579 [00:00&lt;00:00, 43.9kB/s]"}},"f63fdd7ed2a4481b8927b75cbeb5b079":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a44250ea8ca74c4bbef8605f8a87aabe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"180a8685f6244815aa28eb938fcec220":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fae4e006d2d443c987ec12704b5cf9b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2267d534bac14e84a5e98e859479d975":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff029217ca6d41ffabec09915cd55706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5af393892594437bbef55af0294fb04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8b19dcba2374369b9ec8c60c60967ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60caca7b4c794d68803001ab0a6342bc","IPY_MODEL_1ecb69a80093464ebb94d696556986fe","IPY_MODEL_1a4b9be19fda45a7bd7ce42ce97f82c1"],"layout":"IPY_MODEL_ee2199973e264e1c8a6c72c469bfd55c"}},"60caca7b4c794d68803001ab0a6342bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd301e3f15354038bc1bfa29ee59c394","placeholder":"​","style":"IPY_MODEL_e9f6596304f24247b026d55d699e12ad","value":"spm.model: 100%"}},"1ecb69a80093464ebb94d696556986fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65b9f2cb2c8c40a5a1bf0e9db9f25d35","max":4305025,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d204c6bd110342b4bea9bf05ee532f9d","value":4305025}},"1a4b9be19fda45a7bd7ce42ce97f82c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c882db831a64692b43f0044810fccf1","placeholder":"​","style":"IPY_MODEL_3c520d4e14bf4c4d86930ca755846387","value":" 4.31M/4.31M [00:00&lt;00:00, 110MB/s]"}},"ee2199973e264e1c8a6c72c469bfd55c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd301e3f15354038bc1bfa29ee59c394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9f6596304f24247b026d55d699e12ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65b9f2cb2c8c40a5a1bf0e9db9f25d35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d204c6bd110342b4bea9bf05ee532f9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c882db831a64692b43f0044810fccf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c520d4e14bf4c4d86930ca755846387":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e689cd07c284307ac8b405215c6bf97":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df943c2847444885acaf5b65304ce55e","IPY_MODEL_2e8f6ad4d5854fca88219a749600869e","IPY_MODEL_42a12c4bf0f14ac8938f5d2fe80fde55"],"layout":"IPY_MODEL_96616eb78e904228b744b2128ab4db3c"}},"df943c2847444885acaf5b65304ce55e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_823784509bad4fc282534b8f204b6532","placeholder":"​","style":"IPY_MODEL_b26a3a2914e04ba3a2d37b8e55154beb","value":"pytorch_model.bin: 100%"}},"2e8f6ad4d5854fca88219a749600869e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_101c08b6021b47e990201554884ac6e9","max":1332809049,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c52aca9c6b394fc19de10c232992dc90","value":1332809049}},"42a12c4bf0f14ac8938f5d2fe80fde55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bbf6df69a20444eb9636aec354611ac","placeholder":"​","style":"IPY_MODEL_c92d42a597c2433b9378ca54df18bb49","value":" 1.33G/1.33G [00:05&lt;00:00, 259MB/s]"}},"96616eb78e904228b744b2128ab4db3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"823784509bad4fc282534b8f204b6532":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b26a3a2914e04ba3a2d37b8e55154beb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"101c08b6021b47e990201554884ac6e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c52aca9c6b394fc19de10c232992dc90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6bbf6df69a20444eb9636aec354611ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c92d42a597c2433b9378ca54df18bb49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}