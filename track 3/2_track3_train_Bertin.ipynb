{"cells":[{"cell_type":"markdown","metadata":{"id":"h1wWTKJIZwNn"},"source":["## Homophobic lyrics detection - Binary Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4084,"status":"ok","timestamp":1713895632373,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"},"user_tz":360},"id":"4jKe6Z88t8cS","outputId":"dc66a208-9163-4845-8e49-01a4dc1e3bda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0e9ZYbX_Zdb"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/HOMO-MEX/task_3')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mju2plfz-9Ol"},"outputs":[],"source":["from config import config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kz1-GDwGWKet"},"outputs":[],"source":["%%capture\n","#! pip install --quiet \"torchvision\" \"torch>==1.10\" \"pytorch-lightning>=1.3\" \"torchmetrics>=0.3\" \"typing-extensions<4,>=3.7.4.3\" \"tf-estimator-nightly==2.8.0.dev2021122109\" \"folium==0.2.1\"\n","! pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5u7HouB5KAH"},"outputs":[],"source":["%%capture\n","!pip install transformers # pre-trained models from https://huggingface.co/"]},{"cell_type":"markdown","metadata":{"id":"bstJaTW7bkVI"},"source":["### Import all the libraries and functions we will use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YZaDj3XPY79"},"outputs":[],"source":["import re\n","import os\n","import time\n","import datetime\n","import random\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoModel\n","\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, SequentialSampler\n","\n","from torchmetrics.classification import MulticlassF1Score, BinaryF1Score\n","\n","pd.set_option('display.max_colwidth',None)"]},{"cell_type":"markdown","metadata":{"id":"Kfv-X7UtcIS6"},"source":["### Environment set up\n"]},{"cell_type":"markdown","metadata":{"id":"uR_76GQMaWO7"},"source":["Select the device where the model is to be trained."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1713894784615,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"},"user_tz":360},"id":"MWmfcRibcSEa","outputId":"aea4d914-ad65-494b-e644-184951159b1b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":7}],"source":["run_on = 'cuda' if torch.cuda.is_available() else 'cpu'\n","DEVICE = torch.device(run_on)\n","DEVICE"]},{"cell_type":"markdown","metadata":{"id":"7cJHIgIpPY8X"},"source":["Set a random seed to ensure that the results are reproducible when attempting to run this *notebook* again."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucyAVWNSPY8c"},"outputs":[],"source":["# set random seed\n","def set_seed(value):\n","    random.seed(value)\n","    np.random.seed(value)\n","    torch.manual_seed(value)\n","    torch.cuda.manual_seed_all(value)\n","\n","set_seed(config.RANDOM_STATE)"]},{"cell_type":"markdown","metadata":{"id":"9yQwYzSucWXF"},"source":["### Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6vZ9M6OneuC"},"outputs":[],"source":["class CustomDataset:\n","  def __init__(self, datapath, version, batch_size, modelname, test_size=0.2):\n","    self.datapath = datapath\n","    self.batch_size = batch_size\n","    self.dataloaders = {}\n","    self.dfs = {}\n","    self.tokenizer = AutoTokenizer.from_pretrained(modelname\n","                                          ,do_lower_case=(True if 'uncased' in modelname else False))\n","    self.prepareData(version)\n","\n","  def prepareData_kfold(self):\n","    df = pd.read_csv(self.datapath, converters={ config.TEXT:str, config.TARGET:str })\n","    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","    df[\"label\"] = df[\"label\"].map({ \"P\": 0, \"NP\": 1 })\n","\n","    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=config.RANDOM_STATE)\n","    kfolds = skf.split(df[config.TEXT], df[config.TARGET])\n","\n","    for i, (train_index, test_index) in enumerate(kfolds):\n","      train = df.iloc[list(train_index)]\n","      test = df.iloc[list(test_index)]\n","\n","      train = train.sample( len(train), random_state=config.RANDOM_STATE )\n","      test = test.sample( len(test), random_state=config.RANDOM_STATE )\n","\n","      self.dfs[i] = { \"train\": train, \"val\": test }\n","      self.dataloaders[i] = { \"train\": self.getTensorDataset(train), \"val\": self.getTensorDataset(test) }\n","\n","    return self.dataloaders\n","\n","  def prepareData(self, version):\n","    dataset_names = [ \"train\", \"dev\", \"test\" ]\n","    for key in dataset_names:\n","      df = pd.read_csv(f\"{self.datapath}{key}_{version}.csv\", converters={ config.TEXT:str })\n","      if key == \"train\":\n","        df = df.sample( len(df), random_state=config.RANDOM_STATE )\n","\n","      inputs, masks = self.tokenize(df[\"text\"])\n","\n","      if config.TARGET in list(df.columns):\n","        df[config.TARGET] = df[config.TARGET].map({ \"P\": 0, \"NP\": 1 })\n","        labels = torch.tensor(df[config.TARGET].to_numpy(), dtype=torch.long)\n","        data = TensorDataset(inputs, masks, labels)\n","      else:\n","        df[config.ID] = df[config.ID].apply(lambda x: int(x.replace(\"_Track3\", \"\")))\n","        ids = torch.tensor(df[config.ID].to_numpy(), dtype=torch.long)\n","        data = TensorDataset(inputs, masks, ids)\n","\n","      sampler = SequentialSampler(data)\n","      self.dfs[key] = df\n","      self.dataloaders[key] = DataLoader(data,\n","                                         sampler=sampler,\n","                                         batch_size=self.batch_size,\n","                                         num_workers=0)\n","      print(\"...dataloader for\", key, \"completed\")\n","    return self.dataloaders\n","\n","  def getTensorDataset(self, dataset):\n","    inputs, masks = self.tokenize(dataset[config.TEXT])\n","    labels = torch.tensor(dataset[config.TARGET].to_numpy(), dtype=torch.float32)\n","    data = TensorDataset(inputs, masks, labels)\n","    sampler = SequentialSampler(data)\n","    dataloader = DataLoader(data, sampler=sampler, batch_size=self.batch_size, num_workers=0)\n","    return dataloader\n","\n","  def tokenize(self, dataset):\n","    input_ids = []\n","    attention_mask = []\n","\n","    for doc in dataset:\n","      encoded_doc = self.tokenizer.encode_plus(doc,\n","                                          add_special_tokens=True,\n","                                          max_length=config.TASK3_MAXLEN,\n","                                          truncation=True,\n","                                          padding=\"max_length\",\n","                                          return_token_type_ids=False\n","                                          )\n","\n","      input_ids.append(encoded_doc['input_ids'])\n","      attention_mask.append(encoded_doc['attention_mask'])\n","\n","    return (torch.tensor(input_ids), torch.tensor(attention_mask))"]},{"cell_type":"markdown","metadata":{"id":"yjxzchnTfs_N"},"source":["### Training\n","\n","This process consists of transforming the words of the messages into features expected by BETO.\n"]},{"cell_type":"code","source":["# PARAMETERS\n","import math\n","\n","# Model\n","NUM_LABELS = 2\n","TARGET_NAMES = [\"P\", \"NP\"]\n","\n","# Training\n","BATCH_SIZE = 8\n","GRADIENT_ACCUMULATOR_SIZE = 4\n","NUM_EPOCHS = 5\n","\n","GET_ATTENTIONS = False\n","GET_HIDDEN_STATES = False\n","DROPOUT = 0.05\n","\n","# Optimizer\n","LR = 4e-5\n","EPS = 1e-10\n","WEIGHT_DECAY = 0\n","BETAS = (0.9, 0.999)\n","AMSGRAD = False\n","\n","# Loss\n","REDUCTION = \"sum\"\n","LABEL_SMOOTHING = 0\n","\n","# Scheduler\n","POWER = 1.0"],"metadata":{"id":"8UkS1XgJF_dT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfsStD_9wlZ8"},"outputs":[],"source":["#fuction to format time\n","def format_time(elapsed):\n","  elapsed_rounded = int(round((elapsed)))\n","  return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","#function to clean cuda memory\n","def clean_cuda_memory(iterable_var):\n","  for elem in iterable_var:\n","    elem.to('cpu')\n","    del elem\n","  torch.cuda.empty_cache()\n","  gc.collect()\n","\n","def get_class_weights(classes_list, labels):\n","  return compute_class_weight('balanced', classes=classes_list, y=labels)\n","\n","#variable to plot the confusion matrix\n","conf = []"]},{"cell_type":"code","source":["class TextClassifier(nn.Module):\n","    def __init__(self, modelpath, freeze_model=False, num_labels=2, get_att=False, get_hs=False, dropout=0.05):\n","        super(TextClassifier, self).__init__()\n","        self.bert = AutoModel.from_pretrained(modelpath\n","                                              ,num_labels=num_labels\n","                                              ,output_attentions=get_att\n","                                              ,output_hidden_states=get_hs)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n","        self.freeze_model = freeze_model\n","\n","        if self.freeze_model:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids\n","                            ,token_type_ids=None\n","                            ,attention_mask=attention_mask)\n","\n","        pooled_output = outputs.pooler_output\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.fc(pooled_output)\n","        return logits"],"metadata":{"id":"JfhU2Zm0-8q7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPq566wnZ8kc"},"outputs":[],"source":["class CustomModel:\n","  def __init__(self, modelpath, class_weights):\n","    self.model = TextClassifier(modelpath, num_labels=NUM_LABELS, get_att=GET_ATTENTIONS, get_hs=GET_HIDDEN_STATES, dropout=DROPOUT)\n","\n","    self.optimizer = torch.optim.Adam(self.model.parameters()\n","                                      ,lr = LR\n","                                      ,eps = EPS\n","                                      ,weight_decay = WEIGHT_DECAY\n","                                      ,betas = BETAS # 0.9, 0.999\n","                                      ,amsgrad = AMSGRAD)\n","\n","    self.criterion = nn.CrossEntropyLoss(weight=class_weights # torch.tensor([5.8, 0.43, 2]).to(device)\n","                                         ,reduction = REDUCTION #sum\n","                                         ,label_smoothing = LABEL_SMOOTHING)\n","\n","  def freeze_all(self):\n","    #Freeze all layers except classifier\n","    for name, param in self.model.named_parameters():\n","      if \"encoder.layer\" in name:\n","        param.requires_grad = False\n","\n","  def unfreeze(self, layers=np.arange(0,13,1)):\n","    self.freeze_all()\n","    #Unfreeze specified layers\n","    for layer_no in layers:\n","      for name, param in self.model.named_parameters():\n","        if \"encoder.layer\" in name and str(layer_no) in name:\n","          param.requires_grad = True\n","\n","  def freeze_embs(self):\n","    for name, param in self.model.named_parameters():\n","      if \"embeddings\" in name:\n","        param.requires_grad = False\n","\n","  def validation(self, val_dataloader):\n","    t0 = time.time()\n","\n","    # We put the model in validation mode\n","    self.model.eval()\n","\n","    # We declare variables\n","    eval_loss = 0\n","    eval_metric = 0\n","    all_logits = []\n","    all_labels = []\n","\n","    # By minibatches\n","    for step, batch in enumerate(val_dataloader):\n","      b_input_ids, b_input_mask, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","      with torch.no_grad():\n","        # We generate the predictions of the model\n","        outputs = self.model(b_input_ids,\n","                            attention_mask=b_input_mask)\n","\n","        loss = self.criterion(outputs, b_labels)\n","\n","        # ...we extract them\n","        logits = torch.argmax(outputs, dim=1).detach().cpu()\n","        b_labels = b_labels.to('cpu')\n","\n","        # Saving logits and labels. They will be useful for the confusion matrix.\n","        #predict_labels = np.argmax(logits, axis=1).flatten()\n","        all_logits.extend(logits.tolist())\n","        all_labels.extend(b_labels.tolist())\n","\n","        eval_loss += loss\n","\n","    # We calculate the F1 score of this batch\n","    scores = MulticlassF1Score(num_classes=2, average=None)(torch.tensor(all_logits), torch.tensor(all_labels))\n","    score = BinaryF1Score()(torch.tensor(all_logits), torch.tensor(all_labels))\n","    # We show the final accuracy for this epoch\n","    print(f\"\\n\\tF1Scores: {scores.tolist()}\")\n","    print(f\"\\n\\tEvalLoss: {eval_loss}\")\n","    print(f\"\\tValidation took: {format_time(time.time() - t0)}\")\n","    return scores, eval_loss\n","\n","\n","  def training(self, n_epochs, train_dataloader, val_dataloader, gradient_accumulator_size=2):\n","    max_step_t = len(train_dataloader)\n","    max_step_v = len(val_dataloader)\n","\n","    scheduler = torch.optim.lr_scheduler.PolynomialLR(self.optimizer\n","                                                      ,total_iters=n_epochs\n","                                                      ,power=POWER)\n","\n","    total_loss = []\n","    total_lr = []\n","\n","    for epoch in range(n_epochs):\n","      # for each epoch...\n","      print(f\"\\nEpoch {epoch + 1} / {n_epochs} :\")\n","      # We save the start time to see how long it takes.\n","      t0 = time.time()\n","      # We reset the loss value for each epoch.\n","      epoch_loss = []\n","\n","      # Training mode.\n","      self.model.train()\n","      self.model.zero_grad()\n","\n","      for step, batch in enumerate(train_dataloader):\n","        batch_loss = 0\n","        b_input_ids, b_input_mask, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        # Propagation forward in the layers\n","        outputs = self.model(b_input_ids,\n","                        attention_mask=b_input_mask)\n","\n","        # We calculate the loss of the present minibatch\n","        loss = self.criterion(outputs, b_labels) #outputs[0]\n","        batch_loss += loss.item()\n","        epoch_loss.append( loss.item() )\n","\n","        # Backpropagation\n","        loss.backward()\n","\n","        # So we can implement gradien accumulator technique\n","        if (step > 0 and step % gradient_accumulator_size == 0) or (step == len(train_dataloader) - 1):\n","          #(this prevents the gradient from becoming explosive)\n","          torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n","\n","          # We update the weights and bias according to the optimizer\n","          self.optimizer.step()\n","          # We clean the gradients for the accumulator batch\n","          self.model.zero_grad()\n","\n","        b_input_ids.to(\"cpu\")\n","        b_input_mask.to(\"cpu\")\n","        b_labels.to(\"cpu\")\n","        del b_input_ids\n","        del b_input_mask\n","        del b_labels\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","        if step % 20 == 0 or step == max_step_t - 1:\n","          print(f\"Batch {step}/{max_step_t} avg loss: {np.sum(epoch_loss) / (step+1):.5f} {np.max(epoch_loss):.5f} {np.min(epoch_loss):.5f}\")\n","\n","      #Update learning rate each end of epoch\n","      scheduler.step()\n","      total_lr.append(scheduler.get_last_lr())\n","      total_loss.append(np.sum(epoch_loss)/len(train_dataloader))\n","\n","      # We calculate the average loss in the current epoch of the training set\n","      print(f\"\\n\\tAverage training loss: {np.sum(epoch_loss)/len(train_dataloader):.5f}\")\n","      print(f\"\\tTraining epoch took: {format_time(time.time() - t0)}\")\n","\n","      print(\"\\n\\tValidation\")\n","      curr_score, curr_eval_loss = self.validation(val_dataloader)\n","\n","    # Display learning rate and loss charts\n","    epoch_axis = np.arange(0, n_epochs) + 1\n","    plt.plot(epoch_axis, total_loss)\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"loss\")\n","    plt.xticks(epoch_axis)\n","    plt.show()\n","\n","    \"\"\"\n","    print(\"\\n\\n\")\n","\n","    plt.plot(epoch_axis, total_lr)\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"learning rate\")\n","    plt.xticks(epoch_axis)\n","    plt.show()\n","    \"\"\"\n","    print(\"\\nTraining complete\")\n","\n","\n","  def testing(self, dataloader):\n","    preds = []\n","    labs = []\n","\n","    with torch.no_grad():\n","      for step, batch in enumerate(dataloader):\n","        test_inputs, test_masks, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        outputs = self.model(test_inputs,\n","                             attention_mask=test_masks)\n","\n","        logits = torch.argmax(outputs, dim=1).detach().cpu()\n","        b_labels = b_labels.to('cpu').tolist()\n","\n","        preds.extend([x.item() for x in logits])\n","        labs.extend(b_labels)\n","\n","    preds = [ \"P\" if pred == 0 else \"NP\" for pred in preds ]\n","    labs = [ str(l) + \"_Track3\" for l in labs ]\n","\n","    dataframe_res = { \"sub_id\": labs, \"label\": preds }\n","    dataframe_res = pd.DataFrame.from_dict(dataframe_res)\n","\n","    return dataframe_res\n","\n","  def metrics_testing(self, dataloader):\n","    preds = []\n","    labs = []\n","\n","    with torch.no_grad():\n","      for step, batch in enumerate(dataloader):\n","        test_inputs, test_masks, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        outputs = self.model(test_inputs,\n","                             attention_mask=test_masks)\n","\n","        logits = torch.argmax(outputs, dim=1).detach().cpu()\n","        b_labels = b_labels.to('cpu').tolist()\n","\n","        preds.extend([x.item() for x in logits])\n","        labs.extend(b_labels)\n","\n","    return preds, labs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibe3moZGu7i1"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","def report_metrics(data):\n","  preds, targets = data[0], data[1]\n","  print(classification_report(targets, preds, target_names=TARGET_NAMES, digits=4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gUjJXYjqcZ4"},"outputs":[],"source":["import gc\n","\n","def fine_tuning_kfold(layers, desc, modelname, num_epochs = 10, embeddings = True, gradient_accumulator_size = 4):\n","  for kfold in datasets.dataloaders:\n","    if kfold > 2:\n","      break\n","\n","    train = datasets.dataloaders[kfold][\"train\"]\n","    dev = datasets.dataloaders[kfold][\"val\"]\n","    train_count = datasets.dfs[kfold][\"train\"][config.TEXT].count()\n","    dev_count = datasets.dfs[kfold][\"val\"][config.TEXT].count()\n","    print(f\"K-Fold: {kfold} -->  train size:{ train_count } val size:{ dev_count }\")\n","    print(\"------------------------\")\n","\n","    class_weights = get_class_weights([0,1], datasets.dfs[kfold][\"train\"][config.TARGET])\n","    print(f\"class weights: {class_weights}\")\n","    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n","    m = CustomModel(modelname, class_weights)\n","    m.unfreeze(layers)\n","\n","    if not embeddings:\n","      m.freeze_embs()\n","\n","    m.model.to(DEVICE)\n","    m.training(num_epochs, train, dev)\n","\n","    # m.model.save_pretrained(f\"{config.MODELPATH}{config.TRAINED_BETO}_{str(kfold)}\")\n","    print(\"Training complete. Validation results:\\n\")\n","    report_metrics(m.testing(dev))\n","\n","    m.model.to(\"cpu\")\n","    del m\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","#TODO : save best model and prepare test results\n","def fine_tuning(layers, desc, modelname, num_epochs = 10, embeddings = True, gradient_accumulator_size = 4):\n","  train = datasets.dataloaders[\"train\"]\n","  dev = datasets.dataloaders[\"dev\"]\n","  test = datasets.dataloaders[\"test\"]\n","\n","  train_count = datasets.dfs[\"train\"][config.TEXT].count()\n","  dev_count = datasets.dfs[\"dev\"][config.TEXT].count()\n","\n","  print(f\"train_size:{ train_count }   val_size:{ dev_count }\")\n","  print(\"------------------------\")\n","\n","  class_weights = get_class_weights([0,1], datasets.dfs[\"train\"][config.TARGET])\n","  print(f\"class weights: {class_weights}\")\n","  class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n","  m = CustomModel(modelname, class_weights)\n","  m.unfreeze(layers)\n","\n","  if not embeddings:\n","    m.freeze_embs()\n","\n","  m.model.to(DEVICE)\n","  m.training(num_epochs, train, dev)\n","  df_res = m.testing(test)\n","  df_res.to_csv(config.TRACK3 + \"tests/test_maria.csv\")\n","  # m.model.save_pretrained(f\"{config.MODELPATH}{config.TRAINED_BETO}_{str(kfold)}\")\n","  print(\"Training complete. Validation results:\\n\")\n","  report_metrics(m.metrics_testing(dev))\n","\n","  m.model.to(\"cpu\")\n","  del m\n","  torch.cuda.empty_cache()\n","  gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuBdOqcl_870","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713902065971,"user_tz":360,"elapsed":11875,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}},"outputId":"e1227957-aded-4443-de56-06c73b82f66f"},"outputs":[{"output_type":"stream","name":"stdout","text":["...dataloader for train completed\n","...dataloader for dev completed\n","...dataloader for test completed\n"]}],"source":["#Obtener datasets\n","datasets = CustomDataset(config.TRACK3,\n","                         version = \"v1\",\n","                         batch_size = BATCH_SIZE,\n","                         modelname = config.C_BERTIN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YL7SvLt3JYmb","colab":{"base_uri":"https://localhost:8080/","height":564},"executionInfo":{"status":"error","timestamp":1713902273240,"user_tz":360,"elapsed":31024,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}},"outputId":"cf36ea3d-6e93-4688-f6bb-ba5b2f0e7c5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_size:1050   val_size:600\n","------------------------\n","class weights: [3.59589041 0.58075221]\n"]},{"output_type":"error","ename":"ReadTimeout","evalue":"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             raise ReadTimeoutError(\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Read timed out. (read timeout={timeout_value})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-87-bb140ac34588>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfine_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all_layers_cased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_BETO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_accumulator_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGRADIENT_ACCUMULATOR_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-27-c463dfc0e580>\u001b[0m in \u001b[0;36mfine_tuning\u001b[0;34m(layers, desc, modelname, num_epochs, embeddings, gradient_accumulator_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"class weights: {class_weights}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-84-8fb6d20a9ee3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, modelpath, class_weights)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCustomModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_LABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_att\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGET_ATTENTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_hs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGET_HIDDEN_STATES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     self.optimizer = torch.optim.Adam(self.model.parameters()\n","\u001b[0;32m<ipython-input-12-22f78caf2f3b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, modelpath, freeze_model, num_labels, get_att, get_hs, dropout)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_att\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_hs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTextClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         self.bert = BertModel.from_pretrained(modelpath\n\u001b[0m\u001b[1;32m      5\u001b[0m                                               \u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                               \u001b[0;34m,\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_att\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3368\u001b[0m                                 \u001b[0;34m**\u001b[0m\u001b[0mhas_file_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m                             }\n\u001b[0;32m-> 3370\u001b[0;31m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_weights_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhas_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m                                 Thread(\n\u001b[1;32m   3372\u001b[0m                                     \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_conversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mhas_file\u001b[0;34m(path_or_repo, filename, revision, proxies, token, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_hf_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"head\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"]}],"source":["layers = [str(x) for x in range(0, 12)]\n","fine_tuning(layers, \"all_layers_cased\", config.C_BERTIN, num_epochs=NUM_EPOCHS, gradient_accumulator_size=GRADIENT_ACCUMULATOR_SIZE)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}