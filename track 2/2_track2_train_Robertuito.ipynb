{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c578aed3f2444ca1a6d803f9117e8561":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9bd34ca32ea4bed95096c111300150f","IPY_MODEL_37d8a3504ce04dee844ff3451f3b8ab0","IPY_MODEL_67c21c11b71445cd9c1be1be1f662e26"],"layout":"IPY_MODEL_9c1698c4824d4bb9b772461a669e16cc"}},"a9bd34ca32ea4bed95096c111300150f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d093a31ea37436eaaa4021bc8bb254e","placeholder":"​","style":"IPY_MODEL_d91e29d59a0245ecb790e4466513604b","value":"tokenizer_config.json: 100%"}},"37d8a3504ce04dee844ff3451f3b8ab0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95ab04802d4d4c938cb8a3eb93046d82","max":319,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7059e3a37174252bc4a0bdd12a8ad63","value":319}},"67c21c11b71445cd9c1be1be1f662e26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8ee4056ef9c41989c1a80227d49c93f","placeholder":"​","style":"IPY_MODEL_f5678b914fee4b2ba49d98eb7f5e8830","value":" 319/319 [00:00&lt;00:00, 13.3kB/s]"}},"9c1698c4824d4bb9b772461a669e16cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d093a31ea37436eaaa4021bc8bb254e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91e29d59a0245ecb790e4466513604b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ab04802d4d4c938cb8a3eb93046d82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7059e3a37174252bc4a0bdd12a8ad63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8ee4056ef9c41989c1a80227d49c93f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5678b914fee4b2ba49d98eb7f5e8830":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d118225d7e741c1b369f371f393cffb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05f66e57bf2b4603a8d8048a348dda51","IPY_MODEL_bb33c7ab489849dc9ba9ef2a2b047a93","IPY_MODEL_9b80bc5d296e4fb1ac3223f4f1c5d51e"],"layout":"IPY_MODEL_19ec3f42054d45f78a62cfdd5089a634"}},"05f66e57bf2b4603a8d8048a348dda51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db385b2ac1534f2fbfe1829d779cba79","placeholder":"​","style":"IPY_MODEL_632e2e8172f147e88cdd9aebfb65b863","value":"tokenizer.json: 100%"}},"bb33c7ab489849dc9ba9ef2a2b047a93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_986b37a4be33455cbaacb2e42cddf6d3","max":828447,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13bb7c02b8124ed5840c21855f33e4b8","value":828447}},"9b80bc5d296e4fb1ac3223f4f1c5d51e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a33ded658c9f4de8a7eaf89e9994cbeb","placeholder":"​","style":"IPY_MODEL_73beb9085b8a4e3c91b40300b7eb266f","value":" 828k/828k [00:00&lt;00:00, 10.1MB/s]"}},"19ec3f42054d45f78a62cfdd5089a634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db385b2ac1534f2fbfe1829d779cba79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"632e2e8172f147e88cdd9aebfb65b863":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"986b37a4be33455cbaacb2e42cddf6d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13bb7c02b8124ed5840c21855f33e4b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a33ded658c9f4de8a7eaf89e9994cbeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73beb9085b8a4e3c91b40300b7eb266f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6921b085746c4e12b037ae3894f23d34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1121121788541b0b5c265bd4828e713","IPY_MODEL_892de5add42d4c499c58451a387c860a","IPY_MODEL_f7e9dab908c847108239f7f4045d1471"],"layout":"IPY_MODEL_d73522875ee2426a87b4e7e891ca7bed"}},"f1121121788541b0b5c265bd4828e713":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea0b1f51269e4b198b367119291678b3","placeholder":"​","style":"IPY_MODEL_831129bea80f42c8b361826b660dfd0f","value":"special_tokens_map.json: 100%"}},"892de5add42d4c499c58451a387c860a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f8f0093017e4b52905859ca2671dbe2","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ee2920bde1f4ae8aff6e4b37a4687bb","value":150}},"f7e9dab908c847108239f7f4045d1471":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1674e5e606ae42dbabdac3f28b0bde12","placeholder":"​","style":"IPY_MODEL_3dcdd1a44b3345929194c324d37b7ec6","value":" 150/150 [00:00&lt;00:00, 7.89kB/s]"}},"d73522875ee2426a87b4e7e891ca7bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea0b1f51269e4b198b367119291678b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"831129bea80f42c8b361826b660dfd0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f8f0093017e4b52905859ca2671dbe2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee2920bde1f4ae8aff6e4b37a4687bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1674e5e606ae42dbabdac3f28b0bde12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dcdd1a44b3345929194c324d37b7ec6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Hate Speech Detection - Multiclass classification"],"metadata":{"id":"LolZyG9YZU-T"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16347,"status":"ok","timestamp":1714280105098,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"},"user_tz":360},"id":"4jKe6Z88t8cS","outputId":"d96c7e14-d72e-4593-b7e5-50b2a18f7108"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0e9ZYbX_Zdb"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/HOMO-MEX/task_2')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mju2plfz-9Ol"},"outputs":[],"source":["from config import config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kz1-GDwGWKet"},"outputs":[],"source":["%%capture\n","#! pip install --quiet \"torchvision\" \"torch>==1.10\" \"pytorch-lightning>=1.3\" \"torchmetrics>=0.3\" \"typing-extensions<4,>=3.7.4.3\" \"tf-estimator-nightly==2.8.0.dev2021122109\" \"folium==0.2.1\"\n","! pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5u7HouB5KAH"},"outputs":[],"source":["%%capture\n","!pip install transformers # pre-trained models from https://huggingface.co/"]},{"cell_type":"markdown","metadata":{"id":"bstJaTW7bkVI"},"source":["### Import all the libraries and functions we will use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YZaDj3XPY79"},"outputs":[],"source":["import re\n","import os\n","import time\n","import datetime\n","import random\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoModel\n","\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, SequentialSampler\n","\n","from torchmetrics.classification import MultilabelF1Score\n","\n","pd.set_option('display.max_colwidth',None)"]},{"cell_type":"markdown","metadata":{"id":"Kfv-X7UtcIS6"},"source":["### Environment set up\n"]},{"cell_type":"markdown","metadata":{"id":"uR_76GQMaWO7"},"source":["Select the device where the model is to be trained."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714280209894,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"},"user_tz":360},"id":"MWmfcRibcSEa","outputId":"62afd086-7132-4691-a135-a1131d65d772"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":7}],"source":["run_on = 'cuda' if torch.cuda.is_available() else 'cpu'\n","DEVICE = torch.device(run_on)\n","DEVICE"]},{"cell_type":"markdown","metadata":{"id":"7cJHIgIpPY8X"},"source":["Set a random seed to ensure that the results are reproducible when attempting to run this *notebook* again."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucyAVWNSPY8c"},"outputs":[],"source":["# set random seed\n","def set_seed(value):\n","    random.seed(value)\n","    np.random.seed(value)\n","    torch.manual_seed(value)\n","    torch.cuda.manual_seed_all(value)\n","\n","set_seed(config.RANDOM_STATE)"]},{"cell_type":"markdown","metadata":{"id":"9yQwYzSucWXF"},"source":["### Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6vZ9M6OneuC"},"outputs":[],"source":["class CustomDataset:\n","  def __init__(self, datapath, version, batch_size, modelname, test_size=0.2):\n","    self.datapath = datapath\n","    self.batch_size = batch_size\n","    self.dataloaders = {}\n","    self.dfs = {}\n","    self.tokenizer = AutoTokenizer.from_pretrained(modelname\n","                                          ,do_lower_case=(True if 'uncased' in modelname else False))\n","    self.prepareData(version)\n","\n","  def prepareData_kfold(self):\n","    df = pd.read_csv(self.datapath, converters={config.TEXT:str})\n","    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","    df[\"labels\"] = df[\"L\"].map(str) + df[\"G\"].map(str) + df[\"B\"].map(str) + df[\"T\"].map(str) + df[\"O\"].map(str) + df[\"NR\"].map(str)\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=config.RANDOM_STATE)\n","    kfolds = skf.split(df[config.TEXT], df[\"labels\"])\n","\n","    for i, (train_index, test_index) in enumerate(kfolds):\n","      train = df.iloc[list(train_index)]\n","      test = df.iloc[list(test_index)]\n","\n","      train = train.sample( len(train), random_state=config.RANDOM_STATE )\n","      test = test.sample( len(test), random_state=config.RANDOM_STATE )\n","\n","      self.dfs[i] = { \"train\": train, \"val\": test }\n","      self.dataloaders[i] = { \"train\": self.getTensorDataset(train), \"val\": self.getTensorDataset(test) }\n","\n","    return self.dataloaders\n","\n","  def prepareData(self, version):\n","    dataset_names = [ \"train\", \"dev\", \"test\" ]\n","    for key in dataset_names:\n","      df = pd.read_csv(f\"{self.datapath}{key}_{version}.csv\", converters={ config.TEXT:str })\n","      if key == \"train\":\n","        df = df.sample( len(df), random_state=config.RANDOM_STATE )\n","\n","      inputs, masks = self.tokenize(df[\"text\"])\n","\n","      if config.TARGETS[0] in list(df.columns):\n","        labels = torch.tensor(df[config.TARGETS].values, dtype=torch.float32)\n","        data = TensorDataset(inputs, masks, labels)\n","      else:\n","        df[config.ID] = df[config.ID].apply(lambda x: int(x.replace(\"_Track2\", \"\")))\n","        ids = torch.tensor(df[config.ID].to_numpy(), dtype=torch.float32)\n","        data = TensorDataset(inputs, masks, ids)\n","\n","      sampler = SequentialSampler(data)\n","      self.dfs[key] = df\n","      self.dataloaders[key] = DataLoader(data,\n","                                         sampler=sampler,\n","                                         batch_size=self.batch_size,\n","                                         num_workers=0)\n","      print(\"...dataloader for\", key, \"completed\")\n","    return self.dataloaders\n","\n","  def getTensorDataset(self, dataset):\n","    inputs, masks = self.tokenize(dataset[config.TEXT])\n","    #labels = torch.tensor(dataset[config.TARGET].to_numpy(), dtype=torch.long)\n","    labels = torch.tensor(dataset[config.TARGETS].values, dtype=torch.float32)\n","    data = TensorDataset(inputs, masks, labels)\n","    sampler = SequentialSampler(data)\n","    dataloader = DataLoader(data, sampler=sampler, batch_size=self.batch_size, num_workers=0)\n","    return dataloader\n","\n","  def tokenize(self, dataset):\n","    input_ids = []\n","    attention_mask = []\n","\n","    for doc in dataset:\n","      encoded_doc = self.tokenizer.encode_plus(doc,\n","                                          add_special_tokens=True,\n","                                          max_length=config.TASK2_MAXLEN,\n","                                          truncation=True,\n","                                          padding=\"max_length\",\n","                                          return_token_type_ids=False\n","                                          )\n","\n","      input_ids.append(encoded_doc['input_ids'])\n","      attention_mask.append(encoded_doc['attention_mask'])\n","\n","    return (torch.tensor(input_ids), torch.tensor(attention_mask))"]},{"cell_type":"markdown","metadata":{"id":"yjxzchnTfs_N"},"source":["### Training\n","\n","This process consists of transforming the words of the messages into features expected by BETO.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jUvOo85Qlg9"},"outputs":[],"source":["# PARAMETERS\n","\n","# Model\n","NUM_LABELS = 6\n","\n","# Training\n","BATCH_SIZE = 8\n","GRADIENT_ACCUMULATOR_SIZE = 1\n","NUM_EPOCHS = 24\n","\n","GET_ATTENTIONS = False\n","GET_HIDDEN_STATES = False\n","DROPOUT = 0.01\n","\n","# Optimizer\n","LR = 5e-5\n","EPS = 1e-10\n","WEIGHT_DECAY = 0\n","BETAS = (0.9, 0.999)\n","AMSGRAD = False\n","\n","# Loss\n","REDUCTION = \"sum\"\n","LABEL_SMOOTHING = 0\n","\n","# Scheduler\n","POWER = 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfsStD_9wlZ8"},"outputs":[],"source":["#fuction to format time\n","def format_time(elapsed):\n","  elapsed_rounded = int(round((elapsed)))\n","  return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","#function to clean cuda memory\n","def clean_cuda_memory(iterable_var):\n","  for elem in iterable_var:\n","    elem.to('cpu')\n","    del elem\n","  torch.cuda.empty_cache()\n","  gc.collect()\n","\n","def get_class_weights(classes_list, labels):\n","  return compute_class_weight('balanced', classes=classes_list, y=labels)\n","\n","#variable to plot the confusion matrix\n","conf = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVspJbZuQsHD"},"outputs":[],"source":["class TextClassifier(nn.Module):\n","  def __init__(self, modelpath, freeze_model=False, num_labels=2, get_att=False, get_hs=False, dropout=0.05):\n","    super(TextClassifier, self).__init__()\n","    self.bert = AutoModel.from_pretrained(modelpath\n","                                          ,num_labels=num_labels\n","                                          ,output_attentions=get_att\n","                                          ,output_hidden_states=get_hs)\n","\n","    self.dropout = nn.Dropout(dropout)\n","    self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n","    self.freeze_model = freeze_model\n","\n","    if self.freeze_model:\n","        for param in self.bert.parameters():\n","            param.requires_grad = False\n","\n","  def forward(self, input_ids, attention_mask):\n","    outputs = self.bert(input_ids=input_ids\n","                        ,token_type_ids=None\n","                        ,attention_mask=attention_mask)\n","\n","    pooled_output = outputs.pooler_output\n","    pooled_output = self.dropout(pooled_output)\n","    logits = self.fc(pooled_output)\n","    return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPq566wnZ8kc"},"outputs":[],"source":["class CustomModel:\n","  def __init__(self, modelpath, class_weights):\n","    self.model = TextClassifier(modelpath, num_labels=NUM_LABELS, get_att=GET_ATTENTIONS, get_hs=GET_HIDDEN_STATES, dropout=DROPOUT)\n","\n","    self.optimizer = torch.optim.Adam(self.model.parameters()\n","                                      ,lr = LR\n","                                      ,eps = EPS\n","                                      ,weight_decay = WEIGHT_DECAY\n","                                      ,betas = BETAS # 0.9, 0.999\n","                                      ,amsgrad = AMSGRAD)\n","\n","    self.criterion = nn.CrossEntropyLoss(weight=class_weights # torch.tensor([5.8, 0.43, 2]).to(device)\n","                                         ,reduction = REDUCTION #sum\n","                                         ,label_smoothing = LABEL_SMOOTHING)\n","\n","  def freeze_all(self):\n","    #Freeze all layers except classifier\n","    for name, param in self.model.named_parameters():\n","      if \"encoder.layer\" in name:\n","        param.requires_grad = False\n","\n","  def unfreeze(self, layers=np.arange(0,13,1)):\n","    self.freeze_all()\n","    #Unfreeze specified layers\n","    for layer_no in layers:\n","      for name, param in self.model.named_parameters():\n","        if \"encoder.layer\" in name and str(layer_no) in name:\n","          param.requires_grad = True\n","\n","  def freeze_embs(self):\n","    for name, param in self.model.named_parameters():\n","      if \"embeddings\" in name:\n","        param.requires_grad = False\n","\n","  def validation(self, val_dataloader):\n","    t0 = time.time()\n","\n","    # We put the model in validation mode\n","    self.model.eval()\n","\n","    # We declare variables\n","    eval_loss = 0\n","    eval_metric = 0\n","    all_logits = []\n","    all_labels = []\n","\n","    # By minibatches\n","    for step, batch in enumerate(val_dataloader):\n","      b_input_ids, b_input_mask, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","      with torch.no_grad():\n","        # We generate the predictions of the model\n","        outputs = self.model(b_input_ids,\n","                            attention_mask=b_input_mask)\n","\n","        loss = self.criterion(outputs, b_labels)\n","\n","        # ...we extract them\n","        logits = torch.round(torch.sigmoid(outputs)).detach().cpu()\n","        b_labels = b_labels.to('cpu')\n","\n","        # Saving logits and labels. They will be useful for the confusion matrix.\n","        #predict_labels = np.argmax(logits, axis=1).flatten()\n","        all_logits.extend(logits.tolist())\n","        all_labels.extend(b_labels.tolist())\n","\n","        eval_loss += loss\n","\n","    # We calculate the F1 score of this batch\n","    scores = MultilabelF1Score(num_labels=NUM_LABELS, average=None)(torch.tensor(all_logits), torch.tensor(all_labels))\n","\n","    # We show the final accuracy for this epoch\n","    print(f\"\\n\\tF1Scores: {scores.tolist()}\")\n","    print(f\"\\n\\tEvalLoss: {eval_loss}\")\n","    print(f\"\\tValidation took: {format_time(time.time() - t0)}\")\n","    return scores, eval_loss\n","\n","\n","  def training(self, n_epochs, train_dataloader, val_dataloader, gradient_accumulator_size=2):\n","    max_step_t = len(train_dataloader)\n","    max_step_v = len(val_dataloader)\n","\n","    scheduler = torch.optim.lr_scheduler.PolynomialLR(self.optimizer\n","                                                      ,total_iters=n_epochs\n","                                                      ,power=POWER)\n","\n","    total_loss = []\n","    total_lr = []\n","\n","    for epoch in range(n_epochs):\n","      # for each epoch...\n","      print(f\"\\nEpoch {epoch + 1} / {n_epochs} :\")\n","      # We save the start time to see how long it takes.\n","      t0 = time.time()\n","      # We reset the loss value for each epoch.\n","      epoch_loss = []\n","\n","      # Training mode.\n","      self.model.train()\n","      self.model.zero_grad()\n","\n","      for step, batch in enumerate(train_dataloader):\n","        batch_loss = 0\n","        b_input_ids, b_input_mask, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        # Propagation forward in the layers\n","        outputs = self.model(b_input_ids,\n","                        attention_mask=b_input_mask)\n","\n","        # We calculate the loss of the present minibatch\n","        loss = self.criterion(outputs, b_labels) #outputs[0]\n","        batch_loss += loss.item()\n","        epoch_loss.append( loss.item() )\n","\n","        # Backpropagation\n","        loss.backward()\n","\n","        # So we can implement gradien accumulator technique\n","        if (step > 0 and step % gradient_accumulator_size == 0) or (step == len(train_dataloader) - 1):\n","          #(this prevents the gradient from becoming explosive)\n","          torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n","\n","          # We update the weights and bias according to the optimizer\n","          self.optimizer.step()\n","          # We clean the gradients for the accumulator batch\n","          self.model.zero_grad()\n","\n","        b_input_ids.to(\"cpu\")\n","        b_input_mask.to(\"cpu\")\n","        b_labels.to(\"cpu\")\n","        del b_input_ids\n","        del b_input_mask\n","        del b_labels\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","        if step % 20 == 0 or step == max_step_t - 1:\n","          print(f\"Batch {step}/{max_step_t} avg loss: {np.sum(epoch_loss) / (step+1):.5f} {np.max(epoch_loss):.5f} {np.min(epoch_loss):.5f}\")\n","\n","      #Update learning rate each end of epoch\n","      scheduler.step()\n","      total_lr.append(scheduler.get_last_lr())\n","      total_loss.append(np.sum(epoch_loss)/len(train_dataloader))\n","\n","      # We calculate the average loss in the current epoch of the training set\n","      print(f\"\\n\\tAverage training loss: {np.sum(epoch_loss)/len(train_dataloader):.5f}\")\n","      print(f\"\\tTraining epoch took: {format_time(time.time() - t0)}\")\n","\n","      print(\"\\n\\tValidation\")\n","      curr_score, curr_eval_loss = self.validation(val_dataloader)\n","\n","    # Display learning rate and loss charts\n","    epoch_axis = np.arange(0, n_epochs) + 1\n","    plt.plot(epoch_axis, total_loss)\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"loss\")\n","    plt.xticks(epoch_axis)\n","    plt.show()\n","\n","    \"\"\"\n","    print(\"\\n\\n\")\n","\n","    plt.plot(epoch_axis, total_lr)\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"learning rate\")\n","    plt.xticks(epoch_axis)\n","    plt.show()\n","    \"\"\"\n","    print(\"\\nTraining complete\")\n","\n","\n","  def testing(self, dataloader):\n","    preds = []\n","    labs = []\n","\n","    with torch.no_grad():\n","      for step, batch in enumerate(dataloader):\n","        test_inputs, test_masks, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        outputs = self.model(test_inputs,\n","                             attention_mask=test_masks)\n","\n","        logits = torch.round(torch.sigmoid(outputs)).detach().cpu()\n","        b_labels = b_labels.to('cpu').tolist()\n","\n","        preds.extend(logits.tolist())\n","        labs.extend(b_labels)\n","\n","    preds = torch.tensor(preds).T\n","    labs = [ str(l) + \"_Track2\" for l in labs ]\n","\n","    dataframe_res = { \"sub_id\": labs }\n","    for idx, key in enumerate(config.TARGETS):\n","      dataframe_res[key] = preds[idx]\n","\n","    dataframe_res = pd.DataFrame.from_dict(dataframe_res)\n","\n","    return dataframe_res\n","\n","  def metrics_testing(self, dataloader):\n","    preds = []\n","    labs = []\n","\n","    with torch.no_grad():\n","      for step, batch in enumerate(dataloader):\n","        test_inputs, test_masks, b_labels = tuple(t.to(DEVICE) for t in batch)\n","\n","        outputs = self.model(test_inputs,\n","                             attention_mask=test_masks)\n","\n","        logits = torch.round(torch.sigmoid(outputs)).detach().cpu()\n","        b_labels = b_labels.to('cpu').tolist()\n","\n","        preds.extend(logits.tolist())\n","        labs.extend(b_labels)\n","\n","    return preds, labs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibe3moZGu7i1"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import hamming_loss\n","from sklearn.metrics import accuracy_score\n","\n","def report_metrics(data):\n","  preds, targets = data[0], data[1]\n","  print(classification_report(targets, preds, target_names=config.TARGETS, digits=4))\n","  print(f\"hamming loss: {hamming_loss(targets, preds)}\")\n","  print(f\"exact match ratio: {accuracy_score(targets, preds)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gUjJXYjqcZ4"},"outputs":[],"source":["import gc\n","\n","def fine_tuning_kfold(layers, desc, modelname, num_epochs = 10, embeddings = True, gradient_accumulator_size = 4):\n","  for kfold in datasets.dataloaders:\n","    if kfold > 2:\n","      break\n","\n","    train = datasets.dataloaders[kfold][\"train\"]\n","    dev = datasets.dataloaders[kfold][\"val\"]\n","    train_count = datasets.dfs[kfold][\"train\"][config.TEXT].count()\n","    dev_count = datasets.dfs[kfold][\"val\"][config.TEXT].count()\n","    print(f\"K-Fold: {kfold} -->  train size:{ train_count } val size:{ dev_count }\")\n","    print(\"------------------------\")\n","\n","    # class_weights = get_class_weights([0,1,2], datasets.dfs[kfold][\"train\"][config.TARGET])\n","    # print(f\"class weights: {class_weights}\")\n","    # class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n","    #m = CustomModel(modelname, class_weights)\n","\n","    class_weights = []\n","    total = len(datasets.dfs[kfold][\"train\"])\n","    for label in config.TARGETS:\n","      samples = datasets.dfs[kfold][\"train\"][label].sum()\n","      class_weights.append( 1/(samples/total) if samples != 0 else 1 )\n","\n","    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n","    m = CustomModel(modelname,class_weights)\n","    m.unfreeze(layers)\n","\n","    if not embeddings:\n","      m.freeze_embs()\n","\n","    m.model.to(DEVICE)\n","    m.training(num_epochs, train, dev)\n","\n","    # m.model.save_pretrained(f\"{config.MODELPATH}{config.TRAINED_BETO}_{str(kfold)}\")\n","    print(\"Training complete. Validation results:\\n\")\n","    report_metrics(m.testing(dev))\n","\n","    m.model.to(\"cpu\")\n","    del m\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","def fine_tuning(layers, desc, modelname, num_epochs = 10, embeddings = True, gradient_accumulator_size = 4):\n","  train = datasets.dataloaders[\"train\"]\n","  dev = datasets.dataloaders[\"dev\"]\n","  test = datasets.dataloaders[\"test\"]\n","\n","  train_count = datasets.dfs[\"train\"][config.TEXT].count()\n","  dev_count = datasets.dfs[\"dev\"][config.TEXT].count()\n","\n","  print(f\"train_size:{ train_count }   val_size:{ dev_count }\")\n","  print(\"------------------------\")\n","\n","  class_weights = []\n","  total = len(datasets.dfs[\"train\"])\n","  for label in config.TARGETS:\n","    samples = datasets.dfs[\"train\"][label].sum()\n","    class_weights.append( 1/(samples/total) if samples != 0 else 1 )\n","  print(f\"class_weights:{class_weights}\")\n","  class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n","  m = CustomModel(modelname, class_weights)\n","  m.unfreeze(layers)\n","\n","  if not embeddings:\n","    m.freeze_embs()\n","\n","  m.model.to(DEVICE)\n","  m.training(num_epochs, train, dev)\n","  df_res = m.testing(test)\n","  df_res.to_csv(config.TRACK2 + \"tests/test_robertuito.csv\")\n","  # m.model.save_pretrained(f\"{config.MODELPATH}{config.TRAINED_BETO}_{str(kfold)}\")\n","  print(\"Training complete. Validation results:\\n\")\n","  report_metrics(m.metrics_testing(dev))\n","\n","  m.model.to(\"cpu\")\n","  del m\n","  torch.cuda.empty_cache()\n","  gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"eIUDQ18nP50P"},"source":["V3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289,"referenced_widgets":["c578aed3f2444ca1a6d803f9117e8561","a9bd34ca32ea4bed95096c111300150f","37d8a3504ce04dee844ff3451f3b8ab0","67c21c11b71445cd9c1be1be1f662e26","9c1698c4824d4bb9b772461a669e16cc","5d093a31ea37436eaaa4021bc8bb254e","d91e29d59a0245ecb790e4466513604b","95ab04802d4d4c938cb8a3eb93046d82","d7059e3a37174252bc4a0bdd12a8ad63","f8ee4056ef9c41989c1a80227d49c93f","f5678b914fee4b2ba49d98eb7f5e8830","3d118225d7e741c1b369f371f393cffb","05f66e57bf2b4603a8d8048a348dda51","bb33c7ab489849dc9ba9ef2a2b047a93","9b80bc5d296e4fb1ac3223f4f1c5d51e","19ec3f42054d45f78a62cfdd5089a634","db385b2ac1534f2fbfe1829d779cba79","632e2e8172f147e88cdd9aebfb65b863","986b37a4be33455cbaacb2e42cddf6d3","13bb7c02b8124ed5840c21855f33e4b8","a33ded658c9f4de8a7eaf89e9994cbeb","73beb9085b8a4e3c91b40300b7eb266f","6921b085746c4e12b037ae3894f23d34","f1121121788541b0b5c265bd4828e713","892de5add42d4c499c58451a387c860a","f7e9dab908c847108239f7f4045d1471","d73522875ee2426a87b4e7e891ca7bed","ea0b1f51269e4b198b367119291678b3","831129bea80f42c8b361826b660dfd0f","7f8f0093017e4b52905859ca2671dbe2","7ee2920bde1f4ae8aff6e4b37a4687bb","1674e5e606ae42dbabdac3f28b0bde12","3dcdd1a44b3345929194c324d37b7ec6"]},"executionInfo":{"elapsed":3476,"status":"ok","timestamp":1714280213930,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"},"user_tz":360},"id":"kuBdOqcl_870","outputId":"2e3abda5-7b42-4662-d52c-db60d633e2a9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c578aed3f2444ca1a6d803f9117e8561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/828k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d118225d7e741c1b369f371f393cffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6921b085746c4e12b037ae3894f23d34"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["...dataloader for train completed\n","...dataloader for dev completed\n","...dataloader for test completed\n"]}],"source":["#Obtener datasets\n","datasets = CustomDataset(config.TRACK2,\n","                         batch_size = BATCH_SIZE,\n","                         version = \"v3\",\n","                         modelname = config.C_ROBERTUITO)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YL7SvLt3JYmb","outputId":"67e7cf77-a962-411d-afbd-1946fd13a3a3","executionInfo":{"status":"ok","timestamp":1714282557411,"user_tz":360,"elapsed":1022996,"user":{"displayName":"Sergio Damian","userId":"14141393108500213286"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["train_size:1069   val_size:862\n","------------------------\n","class_weights:[12.147727272727272, 1.1984304932735426, 106.9, 11.372340425531913, 13.883116883116884, 1]\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 / 24 :\n","Batch 0/134 avg loss: 60.16306 60.16306 60.16306\n","Batch 20/134 avg loss: 86.49536 286.82056 15.77939\n","Batch 40/134 avg loss: 79.95689 352.33023 9.76472\n","Batch 60/134 avg loss: 76.49273 352.33023 7.63103\n","Batch 80/134 avg loss: 69.56167 352.33023 7.63103\n","Batch 100/134 avg loss: 70.45223 805.65576 7.63103\n","Batch 120/134 avg loss: 64.59107 805.65576 5.11214\n","Batch 133/134 avg loss: 60.90330 805.65576 2.99296\n","\n","\tAverage training loss: 60.90330\n","\tTraining epoch took: 0:00:40\n","\n","\tValidation\n","\n","\tF1Scores: [0.15806806087493896, 0.9503738880157471, 0.1818181872367859, 0.3759036064147949, 0.13867822289466858, 0.0]\n","\n","\tEvalLoss: 5425.76708984375\n","\tValidation took: 0:00:03\n","\n","Epoch 2 / 24 :\n","Batch 0/134 avg loss: 30.87557 30.87557 30.87557\n","Batch 20/134 avg loss: 63.50770 410.37976 2.34927\n","Batch 40/134 avg loss: 57.12780 411.20703 2.34927\n","Batch 60/134 avg loss: 51.40191 411.20703 2.34927\n","Batch 80/134 avg loss: 44.78279 411.20703 2.27638\n","Batch 100/134 avg loss: 45.14679 604.38330 1.25759\n","Batch 120/134 avg loss: 39.76574 604.38330 0.97794\n","Batch 133/134 avg loss: 37.72127 604.38330 0.38781\n","\n","\tAverage training loss: 37.72127\n","\tTraining epoch took: 0:00:38\n","\n","\tValidation\n","\n","\tF1Scores: [0.5950413346290588, 0.960824728012085, 0.8333333134651184, 0.8062826991081238, 0.1525000035762787, 0.0]\n","\n","\tEvalLoss: 2529.70166015625\n","\tValidation took: 0:00:03\n","\n","Epoch 3 / 24 :\n","Batch 0/134 avg loss: 34.96420 34.96420 34.96420\n","Batch 20/134 avg loss: 31.72142 229.79315 0.19961\n","Batch 40/134 avg loss: 30.30046 267.77216 0.19961\n","Batch 60/134 avg loss: 28.00126 267.77216 0.19961\n","Batch 80/134 avg loss: 25.12726 267.77216 0.15832\n","Batch 100/134 avg loss: 28.75012 618.50391 0.15832\n","Batch 120/134 avg loss: 24.59635 618.50391 0.15832\n","Batch 133/134 avg loss: 23.59393 618.50391 0.07087\n","\n","\tAverage training loss: 23.59393\n","\tTraining epoch took: 0:00:40\n","\n","\tValidation\n","\n","\tF1Scores: [0.7821229100227356, 0.967428982257843, 0.800000011920929, 0.8449198007583618, 0.2525880038738251, 0.0]\n","\n","\tEvalLoss: 1869.564453125\n","\tValidation took: 0:00:03\n","\n","Epoch 4 / 24 :\n","Batch 0/134 avg loss: 32.74320 32.74320 32.74320\n","Batch 20/134 avg loss: 20.45828 138.75397 0.03081\n","Batch 40/134 avg loss: 22.25344 228.65907 0.03081\n","Batch 60/134 avg loss: 23.00826 228.65907 0.03081\n","Batch 80/134 avg loss: 21.11401 228.65907 0.02057\n","Batch 100/134 avg loss: 22.13330 228.65907 0.00991\n","Batch 120/134 avg loss: 19.41876 228.65907 0.00991\n","Batch 133/134 avg loss: 18.62171 228.65907 0.00269\n","\n","\tAverage training loss: 18.62171\n","\tTraining epoch took: 0:00:38\n","\n","\tValidation\n","\n","\tF1Scores: [0.7407407164573669, 0.9796205163002014, 0.9523809552192688, 0.8432432413101196, 0.7721518874168396, 0.0]\n","\n","\tEvalLoss: 2142.692138671875\n","\tValidation took: 0:00:03\n","\n","Epoch 5 / 24 :\n","Batch 0/134 avg loss: 44.75096 44.75096 44.75096\n","Batch 20/134 avg loss: 18.16622 127.75977 0.00667\n","Batch 40/134 avg loss: 20.58347 206.15642 0.00498\n","Batch 60/134 avg loss: 19.98789 206.15642 0.00498\n","Batch 80/134 avg loss: 19.66273 206.15642 0.00498\n","Batch 100/134 avg loss: 20.51668 230.35078 0.00420\n","Batch 120/134 avg loss: 18.25162 230.35078 0.00369\n","Batch 133/134 avg loss: 18.68558 230.35078 0.00105\n","\n","\tAverage training loss: 18.68558\n","\tTraining epoch took: 0:00:37\n","\n","\tValidation\n","\n","\tF1Scores: [0.9583333134651184, 0.9791955351829529, 0.800000011920929, 0.9221556782722473, 0.739393949508667, 0.0]\n","\n","\tEvalLoss: 1758.931884765625\n","\tValidation took: 0:00:03\n","\n","Epoch 6 / 24 :\n","Batch 0/134 avg loss: 25.11838 25.11838 25.11838\n","Batch 20/134 avg loss: 17.58796 136.08032 0.00236\n","Batch 40/134 avg loss: 18.78214 184.26488 0.00236\n","Batch 60/134 avg loss: 21.14835 207.41402 0.00156\n","Batch 80/134 avg loss: 18.69433 207.41402 0.00156\n","Batch 100/134 avg loss: 21.37261 369.96402 0.00156\n","Batch 120/134 avg loss: 18.29390 369.96402 0.00156\n","Batch 133/134 avg loss: 18.01274 369.96402 0.00057\n","\n","\tAverage training loss: 18.01274\n","\tTraining epoch took: 0:00:40\n","\n","\tValidation\n","\n","\tF1Scores: [0.9722222089767456, 0.9557640552520752, 0.9090909361839294, 0.9681528806686401, 0.9064748287200928, 0.0]\n","\n","\tEvalLoss: 2208.8056640625\n","\tValidation took: 0:00:03\n","\n","Epoch 7 / 24 :\n","Batch 0/134 avg loss: 33.13259 33.13259 33.13259\n","Batch 20/134 avg loss: 26.46100 136.81882 0.00110\n","Batch 40/134 avg loss: 22.48663 150.06657 0.00110\n","Batch 60/134 avg loss: 20.61947 150.06657 0.00110\n","Batch 80/134 avg loss: 18.04077 150.06657 0.00110\n","Batch 100/134 avg loss: 19.43743 211.08386 0.00110\n","Batch 120/134 avg loss: 16.86778 211.08386 0.00110\n","Batch 133/134 avg loss: 15.94282 211.08386 0.00071\n","\n","\tAverage training loss: 15.94282\n","\tTraining epoch took: 0:00:36\n","\n","\tValidation\n","\n","\tF1Scores: [0.8452380895614624, 0.9683195352554321, 0.9523809552192688, 0.9112426042556763, 0.5779816508293152, 0.0]\n","\n","\tEvalLoss: 1668.4173583984375\n","\tValidation took: 0:00:03\n","\n","Epoch 8 / 24 :\n","Batch 0/134 avg loss: 22.16682 22.16682 22.16682\n","Batch 20/134 avg loss: 14.86251 104.05957 0.00188\n","Batch 40/134 avg loss: 18.90616 274.16974 0.00134\n","Batch 60/134 avg loss: 16.49335 274.16974 0.00088\n","Batch 80/134 avg loss: 16.34051 274.16974 0.00088\n","Batch 100/134 avg loss: 21.61111 628.52344 0.00088\n","Batch 120/134 avg loss: 18.49428 628.52344 0.00088\n","Batch 133/134 avg loss: 18.10530 628.52344 0.00056\n","\n","\tAverage training loss: 18.10530\n","\tTraining epoch took: 0:00:40\n","\n","\tValidation\n","\n","\tF1Scores: [0.8333333134651184, 0.9793672561645508, 0.7692307829856873, 0.949999988079071, 0.774193525314331, 0.0]\n","\n","\tEvalLoss: 1408.3912353515625\n","\tValidation took: 0:00:03\n","\n","Epoch 9 / 24 :\n","Batch 0/134 avg loss: 21.41034 21.41034 21.41034\n","Batch 20/134 avg loss: 10.24277 54.88191 0.00179\n","Batch 40/134 avg loss: 13.85866 186.46886 0.00179\n","Batch 60/134 avg loss: 13.34288 186.46886 0.00096\n","Batch 80/134 avg loss: 13.17598 186.46886 0.00095\n","Batch 100/134 avg loss: 14.09993 186.46886 0.00095\n","Batch 120/134 avg loss: 12.15802 186.46886 0.00095\n","Batch 133/134 avg loss: 11.78574 186.46886 0.00058\n","\n","\tAverage training loss: 11.78574\n","\tTraining epoch took: 0:00:41\n","\n","\tValidation\n","\n","\tF1Scores: [0.7675675749778748, 0.9743589758872986, 0.8695651888847351, 0.8876404762268066, 0.8767123222351074, 0.0]\n","\n","\tEvalLoss: 1471.4173583984375\n","\tValidation took: 0:00:03\n","\n","Epoch 10 / 24 :\n","Batch 0/134 avg loss: 45.72910 45.72910 45.72910\n","Batch 20/134 avg loss: 16.21384 95.60471 0.00072\n","Batch 40/134 avg loss: 19.02101 275.73300 0.00060\n","Batch 60/134 avg loss: 17.54338 275.73300 0.00054\n","Batch 80/134 avg loss: 15.29395 275.73300 0.00054\n","Batch 100/134 avg loss: 16.38424 275.73300 0.00054\n","Batch 120/134 avg loss: 14.07913 275.73300 0.00054\n","Batch 133/134 avg loss: 14.36772 275.73300 0.00054\n","\n","\tAverage training loss: 14.36772\n","\tTraining epoch took: 0:00:38\n","\n","\tValidation\n","\n","\tF1Scores: [0.7675675749778748, 0.9786648154258728, 0.8695651888847351, 0.9325153231620789, 0.6461538672447205, 0.0]\n","\n","\tEvalLoss: 1149.9879150390625\n","\tValidation took: 0:00:03\n","\n","Epoch 11 / 24 :\n","Batch 0/134 avg loss: 28.37470 28.37470 28.37470\n","Batch 20/134 avg loss: 9.83731 44.94746 0.00159\n","Batch 40/134 avg loss: 12.07977 146.70581 0.00159\n","Batch 60/134 avg loss: 11.52418 146.70581 0.00073\n","Batch 80/134 avg loss: 11.25201 146.70581 0.00068\n","Batch 100/134 avg loss: 11.67882 165.83144 0.00068\n","Batch 120/134 avg loss: 10.03799 165.83144 0.00068\n","Batch 133/134 avg loss: 9.70205 165.83144 0.00038\n","\n","\tAverage training loss: 9.70205\n","\tTraining epoch took: 0:00:42\n","\n","\tValidation\n","\n","\tF1Scores: [0.8421052694320679, 0.9786059260368347, 0.9523809552192688, 0.8404255509376526, 0.8205128312110901, 0.0]\n","\n","\tEvalLoss: 1136.4058837890625\n","\tValidation took: 0:00:03\n","\n","Epoch 12 / 24 :\n","Batch 0/134 avg loss: 28.14737 28.14737 28.14737\n","Batch 20/134 avg loss: 7.96548 33.28358 0.00063\n","Batch 40/134 avg loss: 14.51168 292.78699 0.00050\n","Batch 60/134 avg loss: 13.42220 292.78699 0.00046\n","Batch 80/134 avg loss: 12.21602 292.78699 0.00046\n","Batch 100/134 avg loss: 12.75275 292.78699 0.00046\n","Batch 120/134 avg loss: 11.03451 292.78699 0.00046\n","Batch 133/134 avg loss: 11.01660 292.78699 0.00033\n","\n","\tAverage training loss: 11.01660\n","\tTraining epoch took: 0:00:40\n","\n","\tValidation\n","\n","\tF1Scores: [0.7868852615356445, 0.970648467540741, 0.7142857313156128, 0.9685534834861755, 0.8152866363525391, 0.0]\n","\n","\tEvalLoss: 1110.1968994140625\n","\tValidation took: 0:00:03\n","\n","Epoch 13 / 24 :\n","Batch 0/134 avg loss: 27.90532 27.90532 27.90532\n","Batch 20/134 avg loss: 8.30649 31.76472 0.00061\n","Batch 40/134 avg loss: 11.18820 148.42899 0.00061\n","Batch 60/134 avg loss: 10.89453 148.42899 0.00056\n","Batch 80/134 avg loss: 10.16912 148.42899 0.00056\n","Batch 100/134 avg loss: 10.97259 171.44772 0.00056\n","Batch 120/134 avg loss: 10.00598 171.44772 0.00056\n","Batch 133/134 avg loss: 9.71016 171.44772 0.00056\n","\n","\tAverage training loss: 9.71016\n","\tTraining epoch took: 0:00:41\n","\n","\tValidation\n","\n","\tF1Scores: [0.5853658318519592, 0.977319598197937, 0.9090909361839294, 0.9069767594337463, 0.6888889074325562, 0.0]\n","\n","\tEvalLoss: 1036.0977783203125\n","\tValidation took: 0:00:03\n","\n","Epoch 14 / 24 :\n","Batch 0/134 avg loss: 27.30337 27.30337 27.30337\n","Batch 20/134 avg loss: 9.30263 43.64871 0.00128\n","Batch 40/134 avg loss: 11.43250 160.37715 0.00090\n","Batch 60/134 avg loss: 10.65248 160.37715 0.00057\n","Batch 80/134 avg loss: 9.85588 160.37715 0.00048\n","Batch 100/134 avg loss: 11.30226 192.82373 0.00047\n","Batch 120/134 avg loss: 9.75855 192.82373 0.00047\n","Batch 133/134 avg loss: 9.51534 192.82373 0.00041\n","\n","\tAverage training loss: 9.51534\n","\tTraining epoch took: 0:00:39\n","\n","\tValidation\n","\n","\tF1Scores: [0.9342105388641357, 0.977319598197937, 0.9090909361839294, 0.9230769276618958, 0.6461538672447205, 0.0]\n","\n","\tEvalLoss: 1020.4317016601562\n","\tValidation took: 0:00:03\n","\n","Epoch 15 / 24 :\n","Batch 0/134 avg loss: 20.33215 20.33215 20.33215\n","Batch 20/134 avg loss: 7.59789 32.59161 0.00057\n","Batch 40/134 avg loss: 11.31535 180.15370 0.00057\n","Batch 60/134 avg loss: 10.46060 180.15370 0.00054\n","Batch 80/134 avg loss: 9.61059 180.15370 0.00054\n","Batch 100/134 avg loss: 10.60312 180.15370 0.00045\n","Batch 120/134 avg loss: 9.13130 180.15370 0.00037\n","Batch 133/134 avg loss: 8.89456 180.15370 0.00021\n","\n","\tAverage training loss: 8.89456\n","\tTraining epoch took: 0:00:38\n","\n","\tValidation\n","\n","\tF1Scores: [0.9113923907279968, 0.96875, 0.9523809552192688, 0.9349112510681152, 0.867132842540741, 0.0]\n","\n","\tEvalLoss: 1087.19873046875\n","\tValidation took: 0:00:03\n","\n","Epoch 16 / 24 :\n","Batch 0/134 avg loss: 17.32546 17.32546 17.32546\n","Batch 20/134 avg loss: 8.22037 40.41452 0.00041\n","Batch 40/134 avg loss: 11.73023 169.72388 0.00041\n","Batch 60/134 avg loss: 10.65906 169.72388 0.00041\n","Batch 80/134 avg loss: 9.93778 169.72388 0.00041\n","Batch 100/134 avg loss: 11.23222 231.65552 0.00041\n","Batch 120/134 avg loss: 9.66005 231.65552 0.00041\n","Batch 133/134 avg loss: 9.25898 231.65552 0.00026\n","\n","\tAverage training loss: 9.25898\n","\tTraining epoch took: 0:00:41\n","\n","\tValidation\n","\n","\tF1Scores: [0.7634408473968506, 0.965470552444458, 0.9523809552192688, 0.9629629850387573, 0.837837815284729, 0.0]\n","\n","\tEvalLoss: 959.6638793945312\n","\tValidation took: 0:00:03\n","\n","Epoch 17 / 24 :\n","Batch 0/134 avg loss: 21.95580 21.95580 21.95580\n","Batch 20/134 avg loss: 6.73861 26.10222 0.00045\n","Batch 40/134 avg loss: 9.59613 142.51472 0.00045\n","Batch 60/134 avg loss: 9.48356 142.51472 0.00044\n","Batch 80/134 avg loss: 9.05309 142.51472 0.00044\n","Batch 100/134 avg loss: 9.73888 148.76398 0.00044\n","Batch 120/134 avg loss: 8.41355 148.76398 0.00044\n","Batch 133/134 avg loss: 8.16528 148.76398 0.00024\n","\n","\tAverage training loss: 8.16528\n","\tTraining epoch took: 0:00:38\n","\n","\tValidation\n","\n","\tF1Scores: [0.8520709872245789, 0.9648173451423645, 0.9523809552192688, 0.9873417615890503, 0.8456375598907471, 0.0]\n","\n","\tEvalLoss: 930.5518188476562\n","\tValidation took: 0:00:03\n","\n","Epoch 18 / 24 :\n","Batch 0/134 avg loss: 18.40515 18.40515 18.40515\n","Batch 20/134 avg loss: 7.40106 26.19157 0.00033\n","Batch 40/134 avg loss: 10.59695 149.20653 0.00033\n","Batch 60/134 avg loss: 9.81163 149.20653 0.00033\n","Batch 80/134 avg loss: 9.21823 149.20653 0.00033\n","Batch 100/134 avg loss: 10.10764 157.47255 0.00033\n","Batch 120/134 avg loss: 8.69873 157.47255 0.00033\n","Batch 133/134 avg loss: 8.51830 157.47255 0.00029\n","\n","\tAverage training loss: 8.51830\n","\tTraining epoch took: 0:00:40\n","\n","\tValidation\n","\n","\tF1Scores: [0.7346938848495483, 0.9726775884628296, 0.9523809552192688, 0.9808917045593262, 0.8129032254219055, 0.0]\n","\n","\tEvalLoss: 925.4169311523438\n","\tValidation took: 0:00:03\n","\n","Epoch 19 / 24 :\n","Batch 0/134 avg loss: 22.53369 22.53369 22.53369\n","Batch 20/134 avg loss: 6.55522 23.41854 0.00040\n","Batch 40/134 avg loss: 9.22976 138.56517 0.00030\n","Batch 60/134 avg loss: 9.13614 138.56517 0.00030\n","Batch 80/134 avg loss: 8.50510 138.56517 0.00030\n","Batch 100/134 avg loss: 9.34308 152.91443 0.00030\n","Batch 120/134 avg loss: 8.06494 152.91443 0.00030\n","Batch 133/134 avg loss: 7.86326 152.91443 0.00030\n","\n","\tAverage training loss: 7.86326\n","\tTraining epoch took: 0:00:40\n","\n","\tValidation\n","\n","\tF1Scores: [0.8554216623306274, 0.9772883653640747, 0.9090909361839294, 0.8926553726196289, 0.7777777910232544, 0.0]\n","\n","\tEvalLoss: 896.5924682617188\n","\tValidation took: 0:00:03\n","\n","Epoch 20 / 24 :\n","Batch 0/134 avg loss: 27.82045 27.82045 27.82045\n","Batch 20/134 avg loss: 8.22574 35.45596 0.00038\n","Batch 40/134 avg loss: 10.42656 132.55177 0.00028\n","Batch 60/134 avg loss: 9.87421 132.55177 0.00028\n","Batch 80/134 avg loss: 9.03580 132.55177 0.00028\n","Batch 100/134 avg loss: 9.66825 147.55960 0.00028\n","Batch 120/134 avg loss: 8.32911 147.55960 0.00028\n","Batch 133/134 avg loss: 8.10484 147.55960 0.00028\n","\n","\tAverage training loss: 8.10484\n","\tTraining epoch took: 0:00:38\n","\n","\tValidation\n","\n","\tF1Scores: [0.8674699068069458, 0.9733059406280518, 0.9523809552192688, 0.9753086566925049, 0.7356321811676025, 0.0]\n","\n","\tEvalLoss: 842.0687255859375\n","\tValidation took: 0:00:03\n","\n","Epoch 21 / 24 :\n","Batch 0/134 avg loss: 21.19013 21.19013 21.19013\n","Batch 20/134 avg loss: 6.58736 24.76978 0.00037\n","Batch 40/134 avg loss: 9.45442 142.81749 0.00036\n","Batch 60/134 avg loss: 9.01097 142.81749 0.00033\n","Batch 80/134 avg loss: 8.25343 142.81749 0.00029\n","Batch 100/134 avg loss: 9.13727 147.78435 0.00029\n","Batch 120/134 avg loss: 7.90492 147.78435 0.00029\n","Batch 133/134 avg loss: 7.63804 147.78435 0.00019\n","\n","\tAverage training loss: 7.63804\n","\tTraining epoch took: 0:00:42\n","\n","\tValidation\n","\n","\tF1Scores: [0.8452380895614624, 0.967391312122345, 0.9523809552192688, 0.9873417615890503, 0.8129032254219055, 0.0]\n","\n","\tEvalLoss: 854.9268798828125\n","\tValidation took: 0:00:03\n","\n","Epoch 22 / 24 :\n","Batch 0/134 avg loss: 18.43945 18.43945 18.43945\n","Batch 20/134 avg loss: 6.27379 24.09693 0.00034\n","Batch 40/134 avg loss: 9.35539 141.28583 0.00034\n","Batch 60/134 avg loss: 8.93432 141.28583 0.00034\n","Batch 80/134 avg loss: 8.17687 141.28583 0.00032\n","Batch 100/134 avg loss: 9.29324 180.15710 0.00031\n","Batch 120/134 avg loss: 8.00856 180.15710 0.00031\n","Batch 133/134 avg loss: 7.79115 180.15710 0.00023\n","\n","\tAverage training loss: 7.79115\n","\tTraining epoch took: 0:00:39\n","\n","\tValidation\n","\n","\tF1Scores: [0.822857141494751, 0.9713506102561951, 0.9523809552192688, 0.9937106966972351, 0.8571428656578064, 0.0]\n","\n","\tEvalLoss: 845.5651245117188\n","\tValidation took: 0:00:03\n","\n","Epoch 23 / 24 :\n","Batch 0/134 avg loss: 21.80571 21.80571 21.80571\n","Batch 20/134 avg loss: 6.81141 33.21026 0.00032\n","Batch 40/134 avg loss: 9.32603 136.86490 0.00032\n","Batch 60/134 avg loss: 8.93616 136.86490 0.00032\n","Batch 80/134 avg loss: 8.22192 136.86490 0.00029\n","Batch 100/134 avg loss: 8.99133 148.00790 0.00029\n","Batch 120/134 avg loss: 7.74814 148.00790 0.00029\n","Batch 133/134 avg loss: 7.66678 148.00790 0.00021\n","\n","\tAverage training loss: 7.66678\n","\tTraining epoch took: 0:00:38\n","\n","\tValidation\n","\n","\tF1Scores: [0.8470588326454163, 0.9720136523246765, 0.9523809552192688, 0.9937106966972351, 0.875, 0.0]\n","\n","\tEvalLoss: 844.1903686523438\n","\tValidation took: 0:00:03\n","\n","Epoch 24 / 24 :\n","Batch 0/134 avg loss: 17.18534 17.18534 17.18534\n","Batch 20/134 avg loss: 6.38472 23.60766 0.00030\n","Batch 40/134 avg loss: 9.13043 131.10147 0.00029\n","Batch 60/134 avg loss: 8.69333 131.10147 0.00029\n","Batch 80/134 avg loss: 8.01036 131.10147 0.00029\n","Batch 100/134 avg loss: 8.87241 150.50217 0.00029\n","Batch 120/134 avg loss: 7.66692 150.50217 0.00029\n","Batch 133/134 avg loss: 7.41981 150.50217 0.00020\n","\n","\tAverage training loss: 7.41981\n","\tTraining epoch took: 0:00:41\n","\n","\tValidation\n","\n","\tF1Scores: [0.8674699068069458, 0.9720136523246765, 0.9523809552192688, 0.9937106966972351, 0.8129032254219055, 0.0]\n","\n","\tEvalLoss: 815.9677734375\n","\tValidation took: 0:00:03\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABM1klEQVR4nO3deXhTZdoG8Dt70yXpQvc2pez7jlBAUSmbKCAoqDiiMOOMU5XF7UMHcRuKOooyIojjgMvggiObjCAiVGVTC2WXnbZ0Y2uSrmmavN8fbQMVSts0yUna+3ddudqeJE+eQJPcfc97zisTQggQERER+SC51A0QEREROYtBhoiIiHwWgwwRERH5LAYZIiIi8lkMMkREROSzGGSIiIjIZzHIEBERkc9SSt2Au9ntduTm5iIoKAgymUzqdoiIiKgBhBAoKipCTEwM5PK6x12afZDJzc1FfHy81G0QERGRE7KzsxEXF1fn9c0+yAQFBQGo+ofQ6XQSd0NEREQNYTabER8f7/gcr0uzDzI1u5N0Oh2DDBERkY+pb1oIJ/sSERGRz2KQISIiIp/FIENEREQ+i0GGiIiIfBaDDBEREfksBhkiIiLyWQwyRERE5LMYZIiIiMhnMcgQERGRz2KQISIiIp/FIENEREQ+i0GGiIiIfBaDjJOsNjvOXCjBxWKL1K0QERG1WAwyTpr5eQZu/sc2rN6bI3UrRERELRaDjJMMof4AgOxLpRJ3QkRE1HIxyDipJshkMsgQERFJRvIgk5OTg/vvvx9hYWHQarXo3r07fv31V8f1Qgg8//zziI6OhlarRXJyMo4fPy5hx1USqoNMFoMMERGRZCQNMoWFhRg8eDBUKhW++eYbHD58GG+88QZCQkIct3nttdewaNEiLF26FLt370ZAQABGjhyJ8vJyCTsH4quDzNlLZbDbhaS9EBERtVRKKR/81VdfRXx8PJYvX+7YlpiY6PheCIG33noLf/vb3zBu3DgAwEcffYTIyEisWbMG99xzj8d7rhETrIVSLkOFzY58czligrWS9UJERNRSSTois27dOvTr1w933303IiIi0Lt3b7z//vuO60+fPo38/HwkJyc7tun1egwYMAA7d+68Zk2LxQKz2Vzr4g4KuQxxIVXhhbuXiIiIpCFpkDl16hSWLFmC9u3bY9OmTXjkkUfw+OOP48MPPwQA5OfnAwAiIyNr3S8yMtJx3e+lpqZCr9c7LvHx8W7r3xAWAADIusggQ0REJAVJg4zdbkefPn0wf/589O7dGw8//DD+9Kc/YenSpU7XnDNnDkwmk+OSnZ3two5rM4RyRIaIiEhKkgaZ6OhodOnSpda2zp07IysrCwAQFRUFACgoKKh1m4KCAsd1v6fRaKDT6Wpd3CUhtGpEhodgExERSUPSIDN48GAcPXq01rZjx44hISEBQNXE36ioKGzZssVxvdlsxu7du5GUlOTRXq8lnodgExERSUrSo5ZmzZqFQYMGYf78+Zg0aRJ+/vlnLFu2DMuWLQMAyGQyzJw5E6+88grat2+PxMREzJ07FzExMRg/fryUrQMAEsKqg8zFEok7ISIiapkkDTL9+/fH6tWrMWfOHLz00ktITEzEW2+9hSlTpjhu8/TTT6OkpAQPP/wwjEYjhgwZgo0bN8LPz0/CzqvUjMgUllphLrdC56eSuCMiIqKWRSaEaNZnczObzdDr9TCZTG6ZL9Pvlc24UFyBrx8bgm6xepfXJyIiaoka+vkt+RIFvi6ei0cSERFJhkGmibh4JBERkXQYZJqIi0cSERFJh0GmibhriYiISDoMMk2UUL1MQSaXKSAiIvI4Bpkmqpkjk2MsQ6XNLnE3RERELQuDTBNFBGmgUcphswvkGsulboeIiKhFYZBpIrlcxqUKiIiIJMIg4wIJjkOwuVQBERGRJzHIuABHZIiIiKTBIOMClxePZJAhIiLyJAYZFzBwRIaIiEgSDDIucOWITDNfg5OIiMirMMi4QFxIVZApslTCWGqVuBsiIqKWg0HGBfxUCkTqNAC4eCQREZEnMci4SEJo1VIFnCdDRETkOQwyLsLFI4mIiDyPQcZFaib8Zl7kSfGIiIg8hUHGRXgINhERkecxyLiIgSfFIyIi8jgGGRepGZHJM5fDUmmTuBsiIqKWgUHGRcIC1AhQKyAEcLawTOp2iIiIWgQGGReRyWRcPJKIiMjDGGRciItHEhEReRaDjAvxyCUiIiLPYpBxIUNY1dl9MzkiQ0RE5BEMMi5k4Nl9iYiIPIpBxoWu3LUkhJC4GyIiouaPQcaFYoO1kMuAMqsN54stUrdDRETU7DHIuJBaKUe0XguAu5eIiIg8gUHGxS4vHskgQ0RE5G4MMi7GQ7CJiIg8h0HGxbh4JBERkecwyLgYR2SIiIg8h0HGxRJCq0+KxyBDRETkdgwyLlYzInO+yIKyCpvE3RARETVvDDIupvdXQa9VAeDuJSIiIndjkHEDzpMhIiLyDAYZNzA4ziVTInEnREREzRuDjBtw8UgiIiLPYJBxg5ogwyOXiIiI3ItBxg0SOEeGiIjIIxhk3CC+OsicvVQGu11I3A0REVHzxSDjBjHBWijlMlTY7Mg3l0vdDhERUbPFIOMGCrkMcSFaANy9RERE5E4MMm5iCKtaqoCLRxIREbkPg4ybGEI5IkNERORuDDJuwsUjiYiI3I9Bxk3ieQg2ERGR2zHIuElC9TIFWVymgIiIyG0YZNykZkSmsNQKc7lV4m6IiIiaJwYZNwnUKNEqUA2ARy4RERG5i6RB5oUXXoBMJqt16dSpk+P68vJypKSkICwsDIGBgZg4cSIKCgok7Lhx4rl4JBERkVtJPiLTtWtX5OXlOS4//fST47pZs2Zh/fr1WLVqFdLS0pCbm4sJEyZI2G3jcPFIIiIi91JK3oBSiaioqKu2m0wmfPDBB1i5ciVuvfVWAMDy5cvRuXNn7Nq1CwMHDrxmPYvFAovF4vjZbDa7p/EG4OKRRERE7iX5iMzx48cRExODNm3aYMqUKcjKygIApKenw2q1Ijk52XHbTp06wWAwYOfOnXXWS01NhV6vd1zi4+Pd/hzqwl1LRERE7iVpkBkwYABWrFiBjRs3YsmSJTh9+jRuvPFGFBUVIT8/H2q1GsHBwbXuExkZifz8/DprzpkzByaTyXHJzs5287OoW0L1MgWZnOxLRETkFpLuWho9erTj+x49emDAgAFISEjAF198Aa1W61RNjUYDjUbjqhabpGaOTI6xDJU2O5QKyQfAiIiImhWv+mQNDg5Ghw4dcOLECURFRaGiogJGo7HWbQoKCq45p8YbRQRpoFHKYbML5BrLpW6HiIio2fGqIFNcXIyTJ08iOjoaffv2hUqlwpYtWxzXHz16FFlZWUhKSpKwy4aTy2VcqoCIiMiNJA0yTz75JNLS0nDmzBns2LEDd955JxQKBe69917o9XpMnz4ds2fPxtatW5Geno6HHnoISUlJdR6x5I0SHIdgc6kCIiIiV5N0jszZs2dx77334uLFiwgPD8eQIUOwa9cuhIeHAwAWLlwIuVyOiRMnwmKxYOTIkXj33XelbLnROCJDRETkPpIGmc8+++y61/v5+WHx4sVYvHixhzpyvcuLRzLIEBERuZpXzZFpjgwckSEiInIbBhk3u3JERgghcTdERETNC4OMm8WFVAWZIksljKVWibshIiJqXhhk3MxPpUCkruoEfVw8koiIyLUYZDwgIbRqqQLOkyEiInItBhkP4OKRRERE7sEg4wE1E34zL/KkeERERK7EIOMBPASbiIjIPRhkPMDAk+IRERG5BYOMB9SMyOSZy2GptEncDRERUfPBIOMBYQFqBKgVEAI4W1gmdTtERETNBoOMB8hkMi4eSURE5AYMMh7CxSOJiIhcj0HGQ3jkEhERkesxyHiIIazq7L6ZHJEhIiJyGQYZDzHw7L5EREQuxyDjIVfuWhJCSNwNERFR88Ag4yGxwVrIZUCZ1YbzxRap2yEiImoWGGQ8RK2UI1qvBcDdS0RERK7CIONBlxePZJAhIiJyBQYZD+Ih2ERERK7FIONBXDySiIjItRhkPIgjMkRERK7FIONBCaHVJ8VjkCEiInIJBhkPqhmROV9kQVmFTeJuiIiIfB+DjAfp/VXQa1UAuHuJiIjIFRhkPIzzZIiIiFyHQcbDDI5zyZRI3AkREZHvY5DxMC4eSURE5DoMMh5WE2R45BIREVHTMch4WALnyBAREbkMg4yHxVcHmbOXymC3C4m7ISIi8m0MMh4WE6yFUi5Dhc2OfHO51O0QERH5NAYZD1PIZYgL0QLg7iUiIqKmYpCRgCGsaqkCLh5JRETUNAwyEjCEckSGiIjIFRhkJMDFI4mIiFyDQUYC8TwEm4iIyCUYZCSQUL1MQRaXKSAiImoSBhkJ1IzIFJZaYS63StwNERGR72KQkUCgRolWgWoAPHKJiIioKRhkJBLPxSOJiIiajEFGIlw8koiIqOkYZCTCxSOJiIiajkFGIty1RERE1HQMMhJJqF6mIJOTfYmIiJzGICORmjkyOcYyVNrsEndDRETkmxhkJBIRpIFGKYfNLpBrLJe6HSIiIp/EICMRuVzGpQqIiIiaiEFGQgmOQ7C5VAEREZEzGGQkxBEZIiKipmGQkdDlxSMZZIiIiJzhNUFmwYIFkMlkmDlzpmNbeXk5UlJSEBYWhsDAQEycOBEFBQXSNeliBo7IEBERNYlXBJlffvkF7733Hnr06FFr+6xZs7B+/XqsWrUKaWlpyM3NxYQJEyTq0vWuHJERQkjcDRERke+RPMgUFxdjypQpeP/99xESEuLYbjKZ8MEHH+DNN9/Erbfeir59+2L58uXYsWMHdu3aVWc9i8UCs9lc6+Kt4kKqgkyRpRLGUqvE3RAREfkeyYNMSkoKxowZg+Tk5Frb09PTYbVaa23v1KkTDAYDdu7cWWe91NRU6PV6xyU+Pt5tvTeVn0qBSJ0GABePJCIicoakQeazzz7Dnj17kJqaetV1+fn5UKvVCA4OrrU9MjIS+fn5ddacM2cOTCaT45Kdne3qtl0qIbRqqQLOkyEiImo8pVQPnJ2djRkzZmDz5s3w8/NzWV2NRgONRuOyeu4WH+qPn89c4uKRRERETpBsRCY9PR3nzp1Dnz59oFQqoVQqkZaWhkWLFkGpVCIyMhIVFRUwGo217ldQUICoqChpmnaDmgm/mRd5UjwiIqLGkmxEZtiwYThw4ECtbQ899BA6deqEZ555BvHx8VCpVNiyZQsmTpwIADh69CiysrKQlJQkRctuwUOwiYiInCdZkAkKCkK3bt1qbQsICEBYWJhj+/Tp0zF79myEhoZCp9PhscceQ1JSEgYOHChFy25h4EnxiIiInCZZkGmIhQsXQi6XY+LEibBYLBg5ciTeffddqdtyqZoRmTxzOSyVNmiUCok7IiIi8h0y0czPxGY2m6HX62EymaDT6aRu5ypCCHSbtwklFTZseWIo2oYHSt0SERGR5Br6+S35eWRaOplMxsUjiYiInMQg4wW4eCQREZFzGGS8AI9cIiIicg6DjBcwhFWd3TeTIzJERESNwiDjBWpGZHh2XyIiosZhkPECV+5aauYHkREREbkUg4wXiA3WQiGXocxqQ56pXOp2iIiIfAaDjBdQK+XoGBkEANiXbZS2GSIiIh/CIOMl+iQEAwD2ZBVK2wgREZEPYZDxEr3jQwAAe7KM0jZCRETkQxhkvESfhKogcyDHhIpKu8TdEBER+QYGGS/ROswfIf4qVFTacTjPLHU7REREPoFBxkvIZDL0NlSNyuzlPBkiIqIGYZDxIr3jgwFwngwREVFDMch4kZp5MhyRISIiahgGGS/SI04PmQw4W1iGc0U8MR4REVF9GGS8SJCfynFivL3cvURERFQvBhkvUzPhlyfGIyIiqh+DjJfpbQgGwBEZIiKihmCQ8TJ9qkdk9p81wmrjifGIiIiux6kg8+GHH2LDhg2On59++mkEBwdj0KBByMzMdFlzLVGbVgHQ+SlRbrXjt7wiqdshIiLyak4Fmfnz50Or1QIAdu7cicWLF+O1115Dq1atMGvWLJc22NLI5VecGC+b82SIiIiux6kgk52djXbt2gEA1qxZg4kTJ+Lhhx9GamoqfvzxR5c22BLVzJPZk8kgQ0REdD1OBZnAwEBcvHgRAPDtt99i+PDhAAA/Pz+UlZW5rrsWqo9jRMYobSNEREReTunMnYYPH44//vGP6N27N44dO4bbbrsNAHDo0CG0bt3alf21SD2rlyrIvFiKC8UWtArUSNsQERGRl3JqRGbx4sVISkrC+fPn8d///hdhYWEAgPT0dNx7770ubbAl0mtVaB8RCADI4GHYREREdXJqRCY4OBjvvPPOVdtffPHFJjdEVXobgnH8XDH2ZBUiuUuk1O0QERF5JadGZDZu3IiffvrJ8fPixYvRq1cv3HfffSgs5ARVV3DMk+GIDBERUZ2cCjJPPfUUzGYzAODAgQN44okncNttt+H06dOYPXu2SxtsqWpWwt531ohKnhiPiIjompzatXT69Gl06dIFAPDf//4Xt99+O+bPn489e/Y4Jv5S07QLD0SQRokiSyWOFhSha4xe6paIiIi8jlMjMmq1GqWlpQCA7777DiNGjAAAhIaGOkZqqGnkchl6cd0lIiKi63IqyAwZMgSzZ8/Gyy+/jJ9//hljxowBABw7dgxxcXEubbAl6119GDZXwiYiIro2p4LMO++8A6VSiS+//BJLlixBbGwsAOCbb77BqFGjXNpgS9a7ep4MD8EmIiK6NqfmyBgMBnz99ddXbV+4cGGTG6LLakZkTl0oQWFJBUIC1NI2RERE5GWcCjIAYLPZsGbNGhw5cgQA0LVrV4wdOxYKhcJlzbV0wf5qtAkPwKnzJcjINuKWThFSt0RERORVnAoyJ06cwG233YacnBx07NgRAJCamor4+Hhs2LABbdu2dWmTLVnv+BCcOl+CPVmFDDJERES/49Qcmccffxxt27ZFdnY29uzZgz179iArKwuJiYl4/PHHXd1ji9YnIRgAj1wiIiK6FqdGZNLS0rBr1y6EhoY6toWFhWHBggUYPHiwy5qjqhEZAMjINsJmF1DIZRJ3RERE5D2cGpHRaDQoKiq6antxcTHUak5IdaWOUUEIUCtQbKnE8XNX/5sTERG1ZE4Fmdtvvx0PP/wwdu/eDSEEhBDYtWsX/vKXv2Ds2LGu7rFFU8hl6Fl99BJ3LxEREdXmVJBZtGgR2rZti6SkJPj5+cHPzw+DBg1Cu3bt8NZbb7m4RepdfYbfPZk8MR4REdGVnJojExwcjLVr1+LEiROOw687d+6Mdu3aubQ5quJYCTvbKG0jREREXqbBQaa+Va23bt3q+P7NN990viO6Sq/qXUsnzhXDVGqF3l8lbUNEREReosFBZu/evQ26nUzGo2pcLSxQg9Zh/jhzsRQZZ40Y2iFc6paIiIi8QoODzJUjLuR5vQ0hOHOxFHsyCxlkiIiIqjk12Zc8r0/1hF/OkyEiIrqMQcZH9K6Z8JtVCLtdSNwNERGRd2CQ8RGdooKgVSlQVF6Jk+eLpW6HiIjIKzDI+AilQo4ecXoAPDEeERFRDQYZH1Kze2lPFk+MR0REBDDI+BTHhF+OyBAREQGQOMgsWbIEPXr0gE6ng06nQ1JSEr755hvH9eXl5UhJSUFYWBgCAwMxceJEFBQUSNixtGpGZI6dK4K53CpxN0RERNKTNMjExcVhwYIFSE9Px6+//opbb70V48aNw6FDhwAAs2bNwvr167Fq1SqkpaUhNzcXEyZMkLJlSYUHaRAfqoUQwP5sk9TtEBERSU4mhPCqY3lDQ0Px+uuv46677kJ4eDhWrlyJu+66CwDw22+/oXPnzti5cycGDhzYoHpmsxl6vR4mkwk6nc6drXvE45/uxbp9uZg9vAMeH9Ze6naIiIjcoqGf314zR8Zms+Gzzz5DSUkJkpKSkJ6eDqvViuTkZMdtOnXqBIPBgJ07d9ZZx2KxwGw217o0J5fnyXDCLxERkeRB5sCBAwgMDIRGo8Ff/vIXrF69Gl26dEF+fj7UajWCg4Nr3T4yMhL5+fl11ktNTYVer3dc4uPj3fwMPKv3FSthe9lgGhERkcdJHmQ6duyIjIwM7N69G4888gimTp2Kw4cPO11vzpw5MJlMjkt2drYLu5Ve52gdNEo5jKVWnLpQInU7REREkmrwopHuolar0a5dOwBA37598csvv+Dtt9/G5MmTUVFRAaPRWGtUpqCgAFFRUXXW02g00Gg07m5bMmqlHN1j9fg1sxB7s4xoGx4odUtERESSkXxE5vfsdjssFgv69u0LlUqFLVu2OK47evQosrKykJSUJGGH0uuTwBPjERERARKPyMyZMwejR4+GwWBAUVERVq5ciW3btmHTpk3Q6/WYPn06Zs+ejdDQUOh0Ojz22GNISkpq8BFLzRVPjEdERFRF0iBz7tw5PPDAA8jLy4Ner0ePHj2wadMmDB8+HACwcOFCyOVyTJw4ERaLBSNHjsS7774rZcteoWbC79F8M4otlQjUSL6HkIiISBJedx4ZV2tu55GpMXjB98gxlmHlnwZgUNtWUrdDRETkUj53HhlqnF7cvURERMQg46v61JxPhhN+iYioBWOQ8VG9q0dk9mTxxHhERNRyMcj4qK4xOqgVclwqqUDmxVKp2yEiIpIEg4yP0igV6BpbNflpbzZ3LxERUcvEIOPDaubJ7Mk0StsIERGRRBhkfFjNPBmOyBARUUvFIOPDakZkjuQVobSiUuJuiIiIPI9BxofFBGsRpfODzS5w4KxJ6naIiIg8jkHGx115GDYREVFLwyDj43hiPCIiaskYZHwcT4xHREQtGYOMj+sWq4dKIcOFYgvOFpZJ3Q4REZFHMcj4OD+VAl2iq06Mt4e7l4iIqIVhkGkGejvmyRilbYSIiMjDGGSaAceJ8TgiQ0RELQyDTDNQc+TSoVwzyq02ibshIiLyHAaZZiAuRItWgRpU2gUO5vDEeERE1HIwyDQDMpkMfRyHYXP3EhERtRwMMs1EnwRO+CUiopaHQaaZ6B0fDKBqRIYnxiMiopaCQaaZ6BEXDIVchgKzBXmmcqnbISIi8ggGmWZCq1agc3QQAM6TISKiloNBphmpOQx7T6ZR2kaIiIg8hEGmGXGcGC+bIzJERNQyMMg0I44T4+WYYankifGIiKj5Y5BpRgyh/ggNUKPCZsehXLPU7RAREbkdg0wzUuvEeJncvURERM0fg0wz41gJO9sobSNEREQewCDTzDgm/HJEhoiIWgAGmWamZ1ww5DIg11SOfJ4Yj4iImjkGmWYmQKNExygdAGAvT4xHRETNHINMM8SVsImIqKVgkGmGbkgMBQCsSj+Li8UWibshIiJyHwaZZui27tHoHK2DsdSKv284InU7REREbsMg0wypFHKkTugOmQz4am8Ofjp+QeqWiIiI3IJBppnqFR+MqUmtAQDPrTmAciuXLCAiouaHQaYZe2JEB0Tp/JB5sRTvfH9C6naIiIhcjkGmGQvyU+GFsV0BAEvTTuJYQZHEHREREbkWg0wzN6pbFIZ3iUSlXWDOVwdgtwupWyIiInIZBpkW4MWxXRGgViA9sxCf/ZItdTtEREQuwyDTAsQEa/HEiI4AgNRvjuBcEZcuICKi5oFBpoWYOqg1usfqUVReiZfWH5a6HSIiIpdgkGkhFHIZUid0h1wGfL0/D1uPnpO6JSIioiZjkGlBusXqMW1wIgBg7pqDKK2olLgjIiKipmGQaWFmDe+A2GAtzhaW4e3vjkvdDhERUZMwyLQwARolXhpXdW6Zf/10GodzzRJ3RERE5DwGmRZoWOdI3NY9Cja7wJzVB2DjuWWIiMhHMci0UPPu6IogjRL7so34ZFem1O0QERE5hUGmhYrU+eHpUVXnlnl901Hkm3huGSIi8j0MMi3YlAEJ6BUfjGJLJV5Yd0jqdoiIiBqNQaYFk1efW0Ypl2HjoXxsPlwgdUtERESNImmQSU1NRf/+/REUFISIiAiMHz8eR48erXWb8vJypKSkICwsDIGBgZg4cSIKCviB6yqdo3X4441tAADPrz2IYgvPLUNERL5D0iCTlpaGlJQU7Nq1C5s3b4bVasWIESNQUlLiuM2sWbOwfv16rFq1CmlpacjNzcWECRMk7Lr5mTGsPeJDtcgzlePNb49J3Q4REVGDyYQQXnPs7fnz5xEREYG0tDTcdNNNMJlMCA8Px8qVK3HXXXcBAH777Td07twZO3fuxMCBA+utaTabodfrYTKZoNPp3P0UfFbasfOY+u+fIZcBa1OGoHucXuqWiIioBWvo57dXzZExmUwAgNDQUABAeno6rFYrkpOTHbfp1KkTDAYDdu7cec0aFosFZrO51oXqN7RDOMb2jIFdAHNW70elzS51S0RERPXymiBjt9sxc+ZMDB48GN26dQMA5OfnQ61WIzg4uNZtIyMjkZ+ff806qamp0Ov1jkt8fLy7W2825t7eBTo/JQ7mmLFixxmp2yEiIqqX1wSZlJQUHDx4EJ999lmT6syZMwcmk8lxyc7OdlGHzV94kAZzbusMAHhz8zHkGMsk7oiIiOj6vCLIPProo/j666+xdetWxMXFObZHRUWhoqICRqOx1u0LCgoQFRV1zVoajQY6na7WhRpucr949G8dgtIKG+atPQgvmkJFRER0FUmDjBACjz76KFavXo3vv/8eiYmJta7v27cvVCoVtmzZ4th29OhRZGVlISkpydPttghyuQzz7+wOlUKG746cw8aD196FR0RE5A0kDTIpKSn45JNPsHLlSgQFBSE/Px/5+fkoK6vapaHX6zF9+nTMnj0bW7duRXp6Oh566CEkJSU16Iglck77yCD8ZWhbAMC8dYdgLrdK3BEREdG1SRpklixZApPJhJtvvhnR0dGOy+eff+64zcKFC3H77bdj4sSJuOmmmxAVFYWvvvpKwq5bhpRb2qF1mD/OFVnwj01H678DERGRBLzqPDLuwPPIOG/7iQuY8q/dkMmA/z4yCH0MIVK3RERELURDP7+VHuyJfMzgdq0woU8svtqTg6dW7cOoblGw2gSsNjsqbQKVdjsqKqu+VlZvt9rsqLRfvk3VtqrbXHnfSL0fescHo1d8MHobgmEI9YdMJpP6KRMRkY/hiAxd16WSCgx7YxsKS907TyY0QI2ecXr0ig9BL0MwesUFQ++vcutjEhGR92ro5zeDDNXr1zOXsG5fLuQyGdRKOZRyGZQKOVRyGVTVP6sUcigVVV9VChmU8qqvVdurbqusvo1SLsPpCyXYm2VERrYRh3PNqLjGmYTbhAdUjdjEB6NXfAg6RQdBpfCKMwYQEZGbMchUY5DxfpZKG47kFWFvViEysqvCTebF0qtup1HK0T1Wj17xwVWjNvHBiA3Weu0uKSEEsi+VITrYjwGMiKiRGGSqMcj4pkslFdiXbcTerELszTZiX7YR5vLKq27XKlCDvgnB+OvN7dAzPtjzjdbBWFqB59YcxIb9eRjTIxqL7+sjdUtERD6FQaYag0zzYLcLnL5YgowsI/ZmV43c/JZXhEp71a+vXAb8eWhbzBjWHn4qhaS9ph07j6e/3IcCs8Wx7evHhqBbLFcUJyJqKAaZagwyzVe51YaDOSZ8tDMT6/blAgDaRQTi9bt6oLcEh4qXVdiQ+s0RfLQzEwDQNjwAUXo/bD9xEcO7ROL9B/p5vCciIl/V0M9v7rgnn+WnUqBf61Asurc3lv2hL8KDNDhxrhgTl+xA6v+OoNxq81gvGdlGjFn0oyPEPDioNTY8fiNeHNsVMhmw+XABDuWaPNYPEVFLwSBDzcKIrlHYPOsmTOgdC7sA3vvhFG5b9CPSMwvd+rhWmx0LNx/DxCU7cOpCCaJ0fvh4+g14YWxX+KkUaBcRhNt7xAAA/rnlhFt7ISJqiRhkqNkI9lfjzcm98K8H+iEiSINT50tw19IdeOXrwyircP3ozMnzVaM/b285DptdYGzPGGyaeRNubB9e63aP3doOMhmw8VA+fss3u7wPIqKWjEGGmp3kLpHYPGso7uobByGAf/10Grct+hG/nLnkkvp2u8CHO85gzKIfsf+sCTo/JRbd2xuL7u19zZP4dYgMwm3dogEA//yeozJERK7EIEPNkt5fhX/c3RPLH+yPKJ0fTl8owaT3duKl9U0bnck3lWPq8p8xb90hlFvtuLF9K3w7ayjG9oy57v0evbUdAOB/B/JwvKDI6ccnIqLaGGSoWbulUwQ2zboJk/pVjc78e/tpjHr7B+w+dbHRtdbty8XIt37Aj8cvwE8lx0vjuuKjaTcgSu9X7307R+swsmskhOCoDBGRKzHIULOn16rw2l09seKh/ojW+yHzYikmL9uFF9YdQmnF1SfZ+z1TqRWPfboXj3+6F6YyK3rG6bHh8RvxQFLrRp1V+PFh7QEA6/fn4sS5YqefDxERXcYgQy3GzR2rRmfuvSEeALBixxmMeutH7DxZ9+jMj8fPY+RbP2D9vlwo5DLMGNYeXz4yCG3DAxv9+F1j9EjuXDUqs3grR2WIiFyBQYZaFJ2fCqkTeuCjaTcgNliLrEuluPf9XZi75iBKLJdHZ8oqbHhh3SH84YOfkW8uR5tWAfjvI4Mwa3iHJq2bNKN6VGZtRg5OXyhp8vMhImrpGGSoRbqpQzg2zrwRUwYYAAAf78rEyLd+wI4TF7Av24gx//wRK3acAQA8kJSADY/fiF4uWMupe5wet3aKgF0A73CuDBFRk3GJAmrxtp+4gKe/3I8cYxkAQCGXwWYXiAjS4PW7e2Joh/B6KjRORrYR4xdvh0Iuw/dPDEVCWIBL6xMRNQdcooCogQa3a4VNs27CHwYmAABsdoExPaLx7aybXB5iAKBXfDCGdgiHzS44V4aIqIk4IkN0hX3ZRhSVV2Jwu7BGHZHUWOmZhZi4ZAeUchm2Pnkz4kP93fZYRES+iCMyRE7oGR+MIe1buTXEAEDfhBDc2L4VKu0C72476dbHIiJqzhhkiCRSc16ZL9OzHfNziIiocRhkiCTSv3UoBrUNg9UmsGQb58oQETmDQYZIQjWjMl/8chZ5Jo7KEBE1FoMMkYQGtgnDDYmhqLDZsZRzZYiIGo1BhkhiM6tHZT79JRsF5nKJuyEi8i0MMkQSS2obhn4JIaiotGNpGkdliIgag0GGSGIymQwzkqtGZVbuzsK5IvePyhSWVODZ1Qfwrx9Puf2xiIjciUGGyAsMadcKvQ3BsFTasSzNveHixLkijH93O1buzsIrG47gu8MFbn08IiJ3YpAh8gIymcxxBNMnuzNxodjilsfZ+ts53Ll4BzIvlkKtrHr5P7v6AEylVrc8HhGRuzHIEHmJmzuEo2ecHuVWO9538S4fIQTe/+EUpn34C4oslbghMRTbnrwZbcIDcK7IghfXH3Lp4xEReQqDDJGXuHJU5uOdmbhUUuGSupZKG576cj/+/r8jEAK4p388Ppk+ADHBWvzj7p6Qy4Cv9uZgM3cxEZEPYpAh8iK3dopAt1gdSitsLpmIe77Igvve340v089CLgPm3dEFqRO6O3Yr9TGE4E83tgFQtYvJWOqa8ERE5CkMMkReRCaT4fFbq0ZlPtxxBoVNGJU5nGvG+MXbkZ5ZiCA/JVY8dAMeGpx41YKYs4Z3QNvwAJwvsuCFddzFRES+hUGGyMsM7xKJztE6lFTY8O/tp52qsfFgPiYu2YEcYxkSWwVgTcpg3NQh/Jq39VMpHLuY1mTk4ttD+U1pn4jIoxhkiLyMTCbDjGHtAAArtp9p1BFFQgj8c8tx/OWTdJRZbbixfSus+etgtA0PvO79ehtC8PBNbQEAz64+2KSRICIiT2KQIfJCI7pEoWNkEIoslQ0elSmrsOHxzzLwxuZjAIAHB7XG8gf7Q++vatD9Zya3R/uIQFwotuAFHsVERD6CQYbIC8nll49g+vf20zCXX39UJt9Ujknv7cT6fblQymWYf2d3vDC2K5SKhr/E/VQKvF69i2ltRi42HuQuJiLyfgwyRF5qdLcotI8IRFF5JVZsP1Pn7TKyjRj7zk84kGNCiL8Kn/xxAO4bYHDqMXvFB+PPQ6t2Mf1tzQGXHQJOROQuDDJEXkoul+HRW6vmynzw02kUXWNUZm1GDia9txPniizoEBmIdY8OwcA2YU163JnJ7dEhMhAXiiswj0cxEZGXY5Ah8mK394hBm/AAmMqs+GhnpmO73S7w2sbfMOOzDFRU2pHcOQL/fWQQ4kP9m/yYGmXVUUwKuQzr9+XimwN5Ta5JROQuDDJEXkwhl+Gx6lGZf/14CiWWShRbKvHnT9Lx7raTAIBHbm6L9/7QD0F+DZvU2xA94oLxl6FVJ8r725qDuOimtZ+IiJqKQYbIy93RIwaJrQJQWGrF65uO4q4lO7D5cAHUSjkWTu6JZ0Z1gkIuq79QIz0+rD06RgbhYkkFnucuJiLyUgwyRF5OqZAj5Zbq88rsOIPf8ovQKlCDzx4eiDt7x7ntca/cxbRhfx7+x11MROSFGGSIfMD4XjFICKua/9ItVod1jw5GH0OI2x+3e5wef7255iimg7jAXUxE5GUYZIh8gFIhx0fTbsAr47th1Z8HISZY67HHfuzW9ugUFYRLJRV4fu1Bjz0uEVFDMMgQ+YiEsADcPzABWrXCo4+rVsodu5j+dyAfX+/P9ejjExFdD4MMEdWrW6weKdW7mJ5fe4i7mIjIazDIEFGDPHrFLqa5aw5CCOGWxzlzoQSp3xzB39YcQHpmodseh4iaB5lo5u8SZrMZer0eJpMJOp1O6naIfNqhXBPGvbMdlXaBf97bG3f0jHFJXbtdIO3YeXy48wy2HT1f67quMTpMTWqNO3rGeHy3GhFJp6Gf3wwyRNQoCzcfw9tbjiPEX4VvZw1FeJDG6VrG0gqs+vUsPt6ViaxLpQAAmQy4uUM4QgLU+Hp/Hioq7QAAvVaFSf3icP/ABCSEBbjkuRCR92KQqcYgQ+RaFZV2jFu8HUfyzBjZNRJL7+8LmaxxJ+Q7lGvCxzszsSYjB+XWqqCi81NiUr943D8wAa1bVQWVSyUV+OLXbHyyKxNnC8sAVAWdoR3C8UBSAm7uEAG5G04GSETS84kg88MPP+D1119Heno68vLysHr1aowfP95xvRAC8+bNw/vvvw+j0YjBgwdjyZIlaN++fYMfg0GGyPWu3MX09j29MK5XbL33qai0Y+OhfHy04wx+zSx0bO8crcPUpASM6xVb564jm11g62/n8NGuTPxw7PKuJ0OoP+4faMCkfvEI9lc3/YkRkdfwiSDzzTffYPv27ejbty8mTJhwVZB59dVXkZqaig8//BCJiYmYO3cuDhw4gMOHD8PPz69Bj8EgQ+Qeb393HAu/O4ZgfxW+nXUTIoKu/ZosMJdj5e4srPw5C+eLqo52UsplGNUtClMHtUa/hJBGjeicvlCCT3ZlYtWv2TCXVwIANEo5xvaMwQNJrdE9Tt/0J0dEkvOJIHMlmUxWK8gIIRATE4MnnngCTz75JADAZDIhMjISK1aswD333NOgugwyRO5htdkxfvF2HMo1Y3iXSCz7w+VdTEII/HKmEB/uPINNB/NRaa96mwkP0mDKAAPuu8GACF3D/hipS2lFJdZl5OKjnZk4nGd2bO9tCMYDSQm4rXs0NEpODibyVQ39/FZ6sKdGOX36NPLz85GcnOzYptfrMWDAAOzcubPOIGOxWGCxXD7HhdlsvubtiKhpVIqqE+WNfecnbD5cgLUZuRjRNRJrM3LxYfWaUDX6tw7BA0mtMbJrFNRK15z1wV+txD03GDC5fzzSMwvx0c5MfHMwD3uzjNibZcQrXx/B5P7xmDIwAbEePBMyEXmW1waZ/Px8AEBkZGSt7ZGRkY7rriU1NRUvvviiW3sjoiqdo3V47Nb2eHPzMcxdcxDPrz3o2N3jp5JjfK9Y/CEpAV1j3Le7RyaToV/rUPRrHYpzRZ3x+c/Z+M/uLOSby/HutpNYmnYSwzpHoo8hBDqtEjo/FXRaFXR+yuqvKui0So7eEPkorw0yzpozZw5mz57t+NlsNiM+Pl7Cjoiat0dubotvD+fjYE7V6Kch1B8PJCXg7r7x0PurPNpLRJAfHhvWHo/c3BbfHSnAhzsysfPURWw+XIDNhwuue1+NUn6NgHN14NH5qRAWoEbnaB1CAjjBmEhqXhtkoqKiAAAFBQWIjo52bC8oKECvXr3qvJ9Go4FG4/x5LYiocVQKOZbe3xcrtp/B4HatMLRDuOSHRCsVcozqFo1R3aJxvKAIq/fmoMBsgbncCnOZFebyyuqvVhRVjyBZKu04X2RxTEhuiNhgLbrH6tE9To9usXp0j9UjlOGGyKO8NsgkJiYiKioKW7ZscQQXs9mM3bt345FHHpG2OSKqJS7EH3+7vYvUbVxT+8ggPD2qU53X2+wCxZbLwcZcVnnNwHPl9jxTObIulSLHWIYcYxk2Hrq8uzs2WItusTp0j70cbsICXf/Hld0ucKHYghxjGXKN5cit7sVUZsUNiaEY3S2Kh6RTiyBpkCkuLsaJEyccP58+fRoZGRkIDQ2FwWDAzJkz8corr6B9+/aOw69jYmJqHaJNRNQUCrkMeq0Kem3jdoOZyqw4lGvCwRwTDuSYcTDHhNMXShzhZtOhy7uyYvR+jlDTLa7qa6t6wk2JpRJ5pjLkVIeUmqCSWx1c8kxlsNqufdDp6r05eH7tQQztEIFxvWKQ3DmSyztQsyXp4dfbtm3DLbfcctX2qVOnYsWKFY4T4i1btgxGoxFDhgzBu+++iw4dOjT4MXj4NRF5irncikPVoeZATlXIOXWh5Jq3jb4i3KiV8ivCSlVwMZVZ6308uQyI0vkhJliLmGAtooP9oFEqsPlwAY5ccUi6v1qBEV0iMa5XLIa0bwWVgusFk/fzufPIuAuDDBFJqajcikO5l8PNgeqRm4a88+r8lIgJ1iK2OqTUfF8TXCKDNFDWEUqOFRRhXUYu1u7LQfalMsf2EH8VbusejXG9YtEvIUTy+UxEdWGQqcYgQ0TepthSicO5ZhzIMeFQjgkCQEzw5ZGV2GAtovV+CPJr+lFfQghkZBuxNiMXX+/Pw4Xiy5OZY/R+uKNnDMb2ikGXaF2j18xyphd3PwY1Hwwy1RhkiIiqVNrs2HXqEtZm5GDjwXwUWSod17UND8C4XrEY2zPGsWhnY9iqJx/nGsuQZyp3fM0zXZ7Tc77IgkidH3rGBaNnfDB6xlftWnNFYKPmh0GmGoMMEdHVyq02bDt6Duv25eK7I+dQUWl3XNczPhhje8bgjh7RiND5QQiBSyUVtQJKrqkMecbLQaXAXO5YiqIxZDKgbXggesYFo1e8Hj3jg9EpSueyM0CT72KQqcYgQ0R0feZyK749VIC1GTnYfuICavKIXAbEhmhxzmyB5YqgUxe5DIjU+SFa74foYC1i9H6I1msRE1z1NTxIg6xLpdiXbcT+syZkZBuRYyy7qo5aIUfnGB16xVUFmx5xwWjTKsBl83kqbXaYyqwoLK3ApRIrLpVUoLC0Av5qBRJbBSCxVQBHibwAg0w1BhkiooY7X2TB/w7kYW1GDvZkGWtd1ypQUx1KageUmq8R15l8fL3H23/WiH1nTdiXbcS+s0YYS68+YitIo0SPeD16xAVXj94EI0rvB5tdwFR2OYxcKqmAsTqg1P65AoWlVbdryBFh4UEaJLYKQJtWAWgTHoDEVoFIbBUAQ6g/R4s8hEGmGoMMEZFzsi+VIs9UjiidHyL1Go+sRyWEQPalMmScNVYFm2wjDuaaUG69ekQoQK1AqdXWoCPArkWvVSE0QI0QfxVC/NUoKq/EqQsltSZE/55CLkN8iLZ65CYQieEBaNsqAInhAYjS+TV6MrMQApZKO0oslSitsKHYUonSikoUW2wotVRW/2yD1WaHVq2AVlV9Udf91U+paBZHozHIVGOQISLybZU2O44VFGNfdbjJyDbiWEERrpySo/NTIiRAjRB/dXU4USM0QIXgWj9f3hasVdU5emQut+LMhRKcOl+CUxdKcPpCCU6dL8bpCyUorbDV2adWpUDr6hGc+BB/2EXVWaOrAokNpRWVKLFUoqTCVvW1+nubE3OL6uOnkjtCj191yPFXK+BXvU2vVSE0UI1QfzVCAi5/DQuo+qrzU0p+hBmDTDUGGSKi5qe0ohK5xnLotSoE+6s8cpI/IQTOFVmqA04xTp+vDjkXSpB1qbTJgUSrUiBAo0CARokAtbLW9wq5DOVWG8qsNpRVVH+12lBe/X1pha1B85gaSimXIdi/JtiofhcGfx8O1QgLVLt8xI5BphqDDBERuZvVZkf2pdLq0ZuqpSrUSjn81QoEapTwrwkmamVVOPldYPGvDitNYbcLlFdeEXR+97UmCJVYbFWTnUuq5g5dKq2o+r60ApeKK1BynVGnujx/exdMG5LYpP5/r6Gf3167aCQREZGvUCnkaBMeiDbhgRjWWZoe5HIZ/NVVoakpyq02GKsnRl8ZdC6WXA48jhBUPclaylXfGWSIiIjIwU+lQJRegSi9X4NuL4SAG6b5NBiDDBERETlNJpNBIeG8YB4MT0RERD6LQYaIiIh8FoMMERER+SwGGSIiIvJZDDJERETksxhkiIiIyGcxyBAREZHPYpAhIiIin8UgQ0RERD6LQYaIiIh8FoMMERER+SwGGSIiIvJZDDJERETks5r96tdCVK0tbjabJe6EiIiIGqrmc7vmc7wuzT7IFBUVAQDi4+Ml7oSIiIgaq6ioCHq9vs7rZaK+qOPj7HY7cnNzERQUBJlM5rK6ZrMZ8fHxyM7Ohk6na9b12Jt31GNv3lHPm3tzdT325h31WlJvVxJCoKioCDExMZDL654J0+xHZORyOeLi4txWX6fTufQ/z5vrsTfvqMfevKOeN/fm6nrszTvqtaTealxvJKYGJ/sSERGRz2KQISIiIp/FIOMkjUaDefPmQaPRNPt67M076rE376jnzb25uh578456Lak3ZzT7yb5ERETUfHFEhoiIiHwWgwwRERH5LAYZIiIi8lkMMkREROSzGGSc8MMPP+COO+5ATEwMZDIZ1qxZ43St1NRU9O/fH0FBQYiIiMD48eNx9OhRp2otWbIEPXr0cJyYKCkpCd98843Tvf3eggULIJPJMHPmTKfu/8ILL0Amk9W6dOrUyel+cnJycP/99yMsLAxarRbdu3fHr7/+6lSt1q1bX9WbTCZDSkpKo2vZbDbMnTsXiYmJ0Gq1aNu2LV5++eV61wu5nqKiIsycORMJCQnQarUYNGgQfvnllwbdt77fVyEEnn/+eURHR0Or1SI5ORnHjx93qtZXX32FESNGICwsDDKZDBkZGU73ZrVa8cwzz6B79+4ICAhATEwMHnjgAeTm5jrV2wsvvIBOnTohICAAISEhSE5Oxu7du53q7ff+8pe/QCaT4a233nK63oMPPnjV79+oUaOc7u3IkSMYO3Ys9Ho9AgIC0L9/f2RlZTlV71qvDZlMhtdff73RtYqLi/Hoo48iLi4OWq0WXbp0wdKlS53+dysoKMCDDz6ImJgY+Pv7Y9SoUXX+/jbk/ba8vBwpKSkICwtDYGAgJk6ciIKCAqfrLVu2DDfffDN0Oh1kMhmMRqNTtS5duoTHHnsMHTt2hFarhcFgwOOPPw6TyeR0b3/+85/Rtm1baLVahIeHY9y4cfjtt9+crldDCIHRo0c3+fOxoRhknFBSUoKePXti8eLFTa6VlpaGlJQU7Nq1C5s3b4bVasWIESNQUlLS6FpxcXFYsGAB0tPT8euvv+LWW2/FuHHjcOjQoSb3+csvv+C9995Djx49mlSna9euyMvLc1x++uknp+oUFhZi8ODBUKlU+Oabb3D48GG88cYbCAkJcareL7/8UquvzZs3AwDuvvvuRtd69dVXsWTJErzzzjs4cuQIXn31Vbz22mv45z//6VRvAPDHP/4Rmzdvxscff4wDBw5gxIgRSE5ORk5OTr33re/39bXXXsOiRYuwdOlS7N69GwEBARg5ciTKy8sbXaukpARDhgzBq6++2qDndb16paWl2LNnD+bOnYs9e/bgq6++wtGjRzF27FinnmeHDh3wzjvv4MCBA/jpp5/QunVrjBgxAufPn3eqXo3Vq1dj165diImJcfq51hg1alSt38NPP/3UqVonT57EkCFD0KlTJ2zbtg379+/H3Llz4efn51S9K3vKy8vDv//9b8hkMkycOLHRtWbPno2NGzfik08+wZEjRzBz5kw8+uijWLduXaN7E0Jg/PjxOHXqFNauXYu9e/ciISEBycnJ13wPbcj77axZs7B+/XqsWrUKaWlpyM3NxYQJE67ZW0PqlZaWYtSoUXj22WevWaOhtXJzc5Gbm4t//OMfOHjwIFasWIGNGzdi+vTpTvfWt29fLF++HEeOHMGmTZsghMCIESNgs9mcqlfjrbfecumSQPUS1CQAxOrVq11W79y5cwKASEtLc0m9kJAQ8a9//atJNYqKikT79u3F5s2bxdChQ8WMGTOcqjNv3jzRs2fPJvVS45lnnhFDhgxxSa1rmTFjhmjbtq2w2+2Nvu+YMWPEtGnTam2bMGGCmDJlilO9lJaWCoVCIb7++uta2/v06SOee+65RtX6/e+r3W4XUVFR4vXXX3dsMxqNQqPRiE8//bRRta50+vRpAUDs3bvX6d6u5eeffxYARGZmZpNrmUwmAUB89913Tvd29uxZERsbKw4ePCgSEhLEwoUL661VV72pU6eKcePGNej+9dWaPHmyuP/++xtdq656vzdu3Dhx6623OlWra9eu4qWXXqq1raG/y7+vd/ToUQFAHDx40LHNZrOJ8PBw8f7779db7/fvt0ajUahUKrFq1SrHbY4cOSIAiJ07dza63pW2bt0qAIjCwsJ669RXq8YXX3wh1Gq1sFqtLqm3b98+AUCcOHHC6Xp79+4VsbGxIi8vz+Wfj3XhiIyXqRkmDA0NbVIdm82Gzz77DCUlJUhKSmpSrZSUFIwZMwbJyclNqgMAx48fR0xMDNq0aYMpU6bUOdRdn3Xr1qFfv364++67ERERgd69e+P9999vcn8AUFFRgU8++QTTpk1z6q+KQYMGYcuWLTh27BgAYN++ffjpp58wevRop/qprKyEzWa76q9prVbr9IhWjdOnTyM/P7/W/61er8eAAQOwc+fOJtV2B5PJBJlMhuDg4CbVqaiowLJly6DX69GzZ0+natjtdvzhD3/AU089ha5duzapnxrbtm1DREQEOnbsiEceeQQXL150qq8NGzagQ4cOGDlyJCIiIjBgwACXDfEXFBRgw4YNdY4E1GfQoEFYt24dcnJyIITA1q1bcezYMYwYMaLRtSwWCwDUem3I5XJoNJoGvTZ+/36bnp4Oq9Va6/XQqVMnGAyGBr0eXPX+3dBaJpMJOp0OSmX9yybWV6+kpATLly9HYmIi4uPjnapXWlqK++67D4sXL0ZUVFS9NVzG7VGpmYMLE6fNZhNjxowRgwcPdrrG/v37RUBAgFAoFEKv14sNGzY0qadPP/1UdOvWTZSVlQkhRJNGZP73v/+JL774Quzbt09s3LhRJCUlCYPBIMxmc6NraTQaodFoxJw5c8SePXvEe++9J/z8/MSKFSuc6u1Kn3/+uVAoFCInJ8ep+9tsNvHMM88ImUwmlEqlkMlkYv78+U3qKSkpSQwdOlTk5OSIyspK8fHHHwu5XC46dOjQqDq//33dvn27ACByc3Nr3e7uu+8WkyZNalStK7ljRKasrEz06dNH3HfffU7XWr9+vQgICBAymUzExMSIn3/+2ene5s+fL4YPH+4YtWvqiMynn34q1q5dK/bv3y9Wr14tOnfuLPr37y8qKysbVavmL2F/f3/x5ptvir1794rU1FQhk8nEtm3bnOrtSq+++qoICQlxvCc0tlZ5ebl44IEHBAChVCqFWq0WH374Yb21rlWvoqJCGAwGcffdd4tLly4Ji8UiFixYIACIESNGXLfWtd5v//Of/wi1Wn3Vbfv37y+efvrpRte7UmNGZBryWXD+/HlhMBjEs88+26R6ixcvFgEBAQKA6NixY4NGY+qq9/DDD4vp06c7fnbl5+P1NPvVr31JSkoKDh482KS/sjt27IiMjAyYTCZ8+eWXmDp1KtLS0tClS5dG18rOzsaMGTOwefPmOvetN8aVIxI9evTAgAEDkJCQgC+++KLRf93Z7Xb069cP8+fPBwD07t0bBw8exNKlSzF16tQm9fnBBx9g9OjR9c55qMsXX3yB//znP1i5ciW6du2KjIwMzJw5EzExMU739vHHH2PatGmIjY2FQqFAnz59cO+99yI9Pd2per7GarVi0qRJEEJgyZIlTte55ZZbkJGRgQsXLuD999/HpEmTsHv3bkRERDSqTnp6Ot5++23s2bPHZXMB7rnnHsf33bt3R48ePdC2bVts27YNw4YNa3Adu90OABg3bhxmzZoFAOjVqxd27NiBpUuXYujQoU3q89///jemTJni9HvCP//5T+zatQvr1q1DQkICfvjhB6SkpCAmJqbRo74qlQpfffUVpk+fjtDQUCgUCiQnJ2P06NH1Tq53xfutu+rVV8tsNmPMmDHo0qULXnjhhSbVmzJlCoYPH468vDz84x//wKRJk7B9+/br/v9eq966devw/fffY+/evfU/QVdze1Rq5uCixJmSkiLi4uLEqVOnmt7UFYYNGyYefvhhp+67evVqAUAoFArHBYCQyWRCoVDU+5diQ/Tr10/83//9X6PvZzAYaiV/IYR49913RUxMTJP6OXPmjJDL5WLNmjVO14iLixPvvPNOrW0vv/yy6NixY5N6E0KI4uJix+jJpEmTxG233dao+//+9/XkyZPXHDm56aabxOOPP96oWldy5YhMRUWFGD9+vOjRo4e4cOFCk2r9Xrt27Ro0Wvb7egsXLnS8Dq58bcjlcpGQkOCy/lq1aiWWLl3aqFoWi0UolUrx8ssv17rd008/LQYNGtSk3n744QcBQGRkZNRb51q1SktLhUqlumq+1/Tp08XIkSOb1JvRaBTnzp0TQghxww03iL/+9a911qnr/XbLli3XHDUxGAzizTffbHS9KzV0RKa+WmazWSQlJYlhw4Y1aFSsMZ8tFotF+Pv7i5UrVza63owZM+p8TQwdOrTex24KzpGRmBACjz76KFavXo3vv/8eiYmJLq1vt9sd+5Eba9iwYThw4AAyMjIcl379+mHKlCnIyMiAQqFoUm/FxcU4efIkoqOjG33fwYMHX3Xo37Fjx5CQkNCknpYvX46IiAiMGTPG6RqlpaWQy2u/tBQKheMv5aYICAhAdHQ0CgsLsWnTJowbN65J9RITExEVFYUtW7Y4tpnNZuzevbvJc6tcoWYk5vjx4/juu+8QFhbm0vrOvj7+8Ic/YP/+/bVeGzExMXjqqaewadMml/R29uxZXLx4sdGvD7Vajf79+7vl9fHBBx+gb9++Ts8rslqtsFqtbnl96PV6hIeH4/jx4/j111+v+dqo7/22b9++UKlUtV4PR48eRVZW1jVfD658/25ILbPZjBEjRkCtVmPdunXXHTVxpjchBIQQ13xN1Ffv//7v/656TQDAwoULsXz58nofuym4a8kJxcXFOHHihOPn06dPIyMjA6GhoTAYDI2qlZKSgpUrV2Lt2rUICgpCfn4+gKoXpVarbVStOXPmYPTo0TAYDCgqKsLKlSuxbds2p99Yg4KC0K1bt1rbAgICEBYWdtX2hnjyySdxxx13ICEhAbm5uZg3bx4UCgXuvffeRteaNWsWBg0ahPnz52PSpEn4+eefsWzZMixbtqzRtWrY7XYsX74cU6dObdDkubrccccd+Pvf/w6DwYCuXbti7969ePPNNzFt2jSna9YcGtmxY0ecOHECTz31FDp16oSHHnqo3vvW9/s6c+ZMvPLKK2jfvj0SExMxd+5cxMTEYPz48Y2udenSJWRlZTnO9VLzYRoVFXXNyX/XqxcdHY277roLe/bswddffw2bzeZ4fYSGhkKtVje4VlhYGP7+979j7NixiI6OxoULF7B48WLk5OTUeYh9fc/196FKpVIhKioKHTt2bHS90NBQvPjii5g4cSKioqJw8uRJPP3002jXrh1GjhzZ6N6eeuopTJ48GTfddBNuueUWbNy4EevXr8e2bduceq5A1YfoqlWr8MYbb1yzRkNrDR06FE899RS0Wi0SEhKQlpaGjz76CG+++aZT9VatWoXw8HAYDAYcOHAAM2bMwPjx4685ebi+91u9Xo/p06dj9uzZCA0NhU6nw2OPPYakpCQMHDiw0fUAID8/H/n5+Y7ncODAAQQFBcFgMNSaKFtfrZoQU1paik8++QRmsxlmsxkAEB4eftUflvXVO3XqFD7//HOMGDEC4eHhOHv2LBYsWACtVovbbrut0c+1rte4wWBw+R/oV3HreE8zVTNE+PvL1KlTG13rWnUAiOXLlze61rRp00RCQoJQq9UiPDxcDBs2THz77beNrnM9TZnsO3nyZBEdHS3UarWIjY0VkydPbtDEsrqsX79edOvWTWg0GtGpUyexbNkyp2sJIcSmTZsEAHH06NEm1TGbzWLGjBnCYDAIPz8/0aZNG/Hcc88Ji8XidM3PP/9ctGnTRqjVahEVFSVSUlKE0Whs0H3r+3212+1i7ty5IjIyUmg0GjFs2LA6/w3qq7V8+fJrXj9v3rxG16vZPXWty9atWxtVq6ysTNx5550iJiZGqNVqER0dLcaOHXvdyb6NfZ3XN9n3evVKS0vFiBEjRHh4uFCpVCIhIUH86U9/Evn5+U739sEHH4h27doJPz8/0bNnz+vuLm1Ivffee09otdp6f+/qq5WXlycefPBBERMTI/z8/ETHjh3FG2+8UeepDuqr9/bbb4u4uDihUqmEwWAQf/vb3+p8rTXk/basrEz89a9/FSEhIcLf31/ceeedIi8vz+l68+bNa9B7fH216vp3ACBOnz7d6N5ycnLE6NGjRUREhFCpVCIuLk7cd9994rfffnP6uV7rPp6Y7CurfjAiIiIin8M5MkREROSzGGSIiIjIZzHIEBERkc9ikCEiIiKfxSBDREREPotBhoiIiHwWgwwRERH5LAYZIiIi8lkMMkTU4mzbtg0ymQxGo1HqVoioiRhkiIiIyGcxyBAREZHPYpAhIo+z2+1ITU1FYmIitFotevbsiS+//BLA5d0+GzZsQI8ePeDn54eBAwfi4MGDtWr897//RdeuXaHRaNC6deurVmW2WCx45plnEB8fD41Gg3bt2uGDDz6odZv09HT069cP/v7+GDRokGO1biLyHQwyRORxqamp+Oijj7B06VIcOnQIs2bNwv3334+0tDTHbZ566im88cYb+OWXXxAeHo477rgDVqsVQFUAmTRpEu655x4cOHAAL7zwAubOnYsVK1Y47v/AAw/g008/xaJFi3DkyBG89957CAwMrNXHc889hzfeeAO//vorlEolpk2b5pHnT0Suw9WvicijLBYLQkND8d133yEpKcmx/Y9//CNKS0vx8MMP45ZbbsFnn32GyZMnAwAuXbqEuLg4rFixApMmTcKUKVNw/vx5fPvtt477P/3009iwYQMOHTqEY8eOoWPHjti8eTOSk5Ov6mHbtm245ZZb8N1332HYsGEAgP/9738YM2YMysrK4Ofn5+Z/BSJyFY7IEJFHnThxAqWlpRg+fDgCAwMdl48++ggnT5503O7KkBMaGoqOHTviyJEjAIAjR45g8ODBteoOHjwYx48fh81mQ0ZGBhQKBYYOHXrdXnr06OH4Pjo6GgBw7ty5Jj9HIvIcpdQNEFHLUlxcDADYsGEDYmNja12n0WhqhRlnabXaBt1OpVI5vpfJZACq5u8Qke/giAwReVSXLl2g0WiQlZWFdu3a1brEx8c7brdr1y7H94WFhTh27Bg6d+4MAOjcuTO2b99eq+727dvRoUMHKBQKdO/eHXa7vdacGyJqnjgiQ0QeFRQUhCeffBKzZs2C3W7HkCFDYDKZsH37duh0OiQkJAAAXnrpJYSFhSEyMhLPPfccWrVqhfHjxwMAnnjiCfTv3x8vv/wyJk+ejJ07d+Kdd97Bu+++CwBo3bo1pk6dimnTpmHRokXo2bMnMjMzce7cOUyaNEmqp05EbsAgQ0Qe9/LLLyM8PBypqak4deoUgoOD0adPHzz77LOOXTsLFizAjBkzcPz4cfTq1Qvr16+HWq0GAPTp0wdffPEFnn/+ebz88suIjo7GSy+9hAcffNDxGEuWLMGzzz6Lv/71r7h48SIMBgOeffZZKZ4uEbkRj1oiIq9Sc0RRYWEhgoODpW6HiLwc58gQERGRz2KQISIiIp/FXUtERETkszgiQ0RERD6LQYaIiIh8FoMMERER+SwGGSIiIvJZDDJERETksxhkiIiIyGcxyBAREZHPYpAhIiIin/X/ukiA721NBUIAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Training complete\n","Training complete. Validation results:\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           L     0.7660    1.0000    0.8675        72\n","           G     0.9481    0.9972    0.9720       714\n","           B     0.9091    1.0000    0.9524        10\n","           T     0.9875    1.0000    0.9937        79\n","           O     0.6923    0.9844    0.8129        64\n","          NR     0.0000    0.0000    0.0000         0\n","\n","   micro avg     0.9114    0.9968    0.9522       939\n","   macro avg     0.7172    0.8303    0.7664       939\n","weighted avg     0.9196    0.9968    0.9548       939\n"," samples avg     0.9484    0.9992    0.9652       939\n","\n","hamming loss: 0.01817478731631864\n","exact match ratio: 0.8932714617169374\n"]}],"source":["layers = [str(x) for x in range(0, 12)]\n","fine_tuning(layers, \"all_layers_cased\", config.C_ROBERTUITO, num_epochs=NUM_EPOCHS, gradient_accumulator_size=GRADIENT_ACCUMULATOR_SIZE)"]}]}